{"path":"iCloudDrive/bks/Number Theory/Number Theory 2/Franz/Algebraic NT/ch2.pdf","text":"Chapter 2 The Ring Z of Integers The next step in constructing the rational numbers from N is the construction of Z, that is, of the (ring of) integers. 2.1 Equivalence Classes and Deﬁnition of Inte- gers Before we can do that, let us say a few words about equivalence relations. Given a set S, a relation ∼ is –mathematically speaking – a subset E ⊆ S × S, and we write s ∼ t for s, t ∈ S if and only if (s, t) ∈ E. For example, if S = {A, B, C} and E = {(A, B), (B, C)}, then A ∼ B and B ∼ C, but A ̸∼ C. An equivalence relation is a relation having the following properties: • reﬂexitivity: s ∼ s for all s ∈ S; • symmetry: if s ∼ t for s, t ∈ S, then t ∼ s; • transitivity: if s ∼ t and t ∼ u for s, t, u ∈ S, then s ∼ u. In terms of the subset E, these properties can be stated as follows: • reﬂexitivity: (s, s) ∈ E for all s ∈ S; • symmetry: if (s, t) ∈ E for s, t ∈ S, then (t, s) ∈ E; • transitivity: if (s, t)(t, u) ∈ E for s, t, u ∈ S, then (s, u) ∈ E. The relation deﬁned on the set {A, B, C} above is not an equivalence relation (why?). For any equivalence relation on a set S we can deﬁne the equivalence class of s ∈ S as the set of all elements to which s is equivalent: [s] = {t ∈ S : t ∼ s}. 14 Lemma 2.1. Equivalence classes are either disjoint or they coincide. Proof. Assume that [s] ∩ [t] is nonempty; then there is an element x ∈ S such that x ∈ [s] and x ∈ [t]. By deﬁnition, this implies x ∼ s and and x ∼ t. Since ∼ is an equivalence relation, we deduce s ∼ x and x ∼ t, hence s ∼ t, so t ∈ [s] and s ∈ [t]. But then [s] ⊆ [t]: y ∈ [s] implies y ∼ s, which together with s ∼ t gives y ∼ t, hence y ∈ [t]. By symmetry, we also have [t] ⊆ [s], hence [s] = [t]. Here’s how to do create integers. We can represent every natural number n as a diﬀerence of two natural numbers in many ways, e.g. 2 = 3 − 1 = 4 − 2 = 5 − 3 = . . .. Thus we can represent 2 by the pairs (2, 0), (3, 1), (4, 2), etc. of natural numbers. If we already knew negative numbers, then of course −2 = 1 − 3 = 2 − 4 = . . . would be represented by the pairs (0, 2), (1, 3), (2, 4), etc. The idea is now to turn everything around and create negative integers using pairs (m, n) of natural numbers. We deﬁne an equivalence relation on the set W = {(m, n) : m, n ∈ N} of such pairs by putting (m, n) = (m ′, n′) if m + n′ = m′ + n. This is indeed an equivalence relation because it is • reﬂexive: (m, n) ∼ (m, n); • symmetric: (m, n) ∼ (m′, n′) =⇒ (n′, m′) ∼ (m, n); • transitive: (n, m) ∼ (n′, m′) and (n′, m′) ∼ (n′′, m′′) =⇒ (n, m) ∼ (n′′, m′′). For example, (m, n) ∼ (m, n) holds because m + n = n + m for m, n ∈ N. Now let [m, n] = {(x, y) : (x, y) ∼ (m, n)} denote the equivalence class of (m, n), and let Z = {[m, n] : m, n ∈ N} denote the set of all equivalence classes. We can make N into a subset of Z by identifying a natural number n with the equivalence class [n, 0]. Moreover, we shall simply write −n for the class [0, n] and put 0 = [0, 0] (this is a generally accepted abuse of notation: the neutral element in any additive group is usually denoted by 0). This ‘identiﬁcation’ can be given a precise mathematical formulation by introducing the map ι : N −→ Z that identiﬁes N with a subset of Z: we put ι(n) = [n, 0]. Now we only are able to ‘identify’ N with its image ι(N) ⊆ Z if ι does not map two natural numbers to the same integer, that is, if ι is injective. Let’s check this: assume that ι(m) = ι(n), i.e., that [m, 0] = [n, 0]. By deﬁnition of these equivalence classes this means that (m, 0) ∼ (n, 0), that is, m+0 = n+0. This implies m = n, hence ι is injective. We remark that Z = {. . . − 3, −2, −1, 0, 1, 2, 3, . . .}. To see this, we have to prove that every (m, n) ∈ W is equivalent to exactly one element in {−2, −1, 0, 1, 2, . . .}. This follows from the Trichotomy Law: for 15 example, if m > n, then m = n + z for some nonzero z ∈ N, hence [m, n] = [n + z, n] = [z, 0] etc. We now show that we can deﬁne addition, multiplication and an order < on Z in such a way that the properties of N proved in Chapter 1 continue to hold. 2.2 Addition We start by deﬁning addition ⊕ on Z. We have to say what [r, s] ⊕ [t, u] is supposed to be. Clearly we would like to have [r, s] = r − s, [t, u] = t − u, so the sum should be r − s + t − u = r + t − (s + u) = [r + t, s + u]. With this idea in mind we now deﬁne [r, s] ⊕ [t, u] = [r + t, s + u], (2.1) where the addition inside the brackets is the addition in N. Now there’s some work to do. First we have to prove that this addition is well deﬁned (this is something that comes up whenever we deﬁne something on equivalence classes). What this means is: assume that [r, s] = [r′, s′] and [t, u] = [t′, u′]. On the one hand, we have [r, s] ⊕ [t, u] = [r + t, s + u]. If we replace the left hand side by [r′, s′] ⊕ [t′, u′], then we clearly get [r′, s′] ⊕ [t′, u′] = [r′ + t′, s′ + u′]. But if our addition is to make any sense, then the right hand sides should be equal because, after all, the left hand sides are. Thus we want to show that [r′ + t′, s′ + u′] = [r + t, s + t]. (2.2) We know that [r, s] = [r′, s′], which by deﬁnition means (r, s) ∼ (r′, s′), that is, r + s ′ = s + r′. Similarly, [t, u] = [t′, u′] implies t + u′ = u + t′. Adding these equations and using commutativity and associativity for natural numbers we get r + t + s ′ + u′ = s + u + r′ + t′, which in turn is equivalent to (2.2). Next we have to show that the two additions agree on N; after all, we are using the very same symbols for natural numbers 1, 2, . . . and their images 1, 2, . . . under ι in Z. This can only work if, for natural numbers m, n, the sum m + n is the same whether evaluated in N or in Z. In other words: we want to be sure that ι(m + n) = ι(m) ⊕ ι(n). This is a straight forward computation: ι(m) ⊕ ι(n) = [m, 0] ⊕ [n, 0] by deﬁnition of ι = [m + n, 0] by (2.1) = ι(m + n) by deﬁnition of ι 16 Now that there is no need to distinguish between the two types of addition anymore, we shall often write + instead of ⊕ for the addition on Z. Of course we have prove that associativity and commutativity also hold for our addition in Z. So why is (x + y) + z = x + (y + z) for all x, y, z ∈ Z? Write x = [r, s], y = [t, u] and z = [v, w] with r, s, t, u, v, w ∈ N. Then (x + y) + z = [r + t, s + u] + [v, w] = [(r + t) + v, (s + u) + w], and similarly x + (y + z) = [r + (t + v), s + (u + w)]. Because addition in N is associative, so is addition in Z (again, observe that there’s no need for invoking induction here). Exercise. Prove that addition on Z is commutative. For deﬁning subtraction x − y in Z, we write x = [r, s] and y = [t, u]; we cannot put x − y = [r − t, s − u] because r − t and s − u might not be natural numbers; but if they were, we would have [r − t, s − u] = [r + u, s + t], and nothing prevents us from deﬁning [r, s] ⊖ [t, u] = [r, s] ⊕ [u, t] = [r + u, s + t]. (2.3) Note that ⊖ is well deﬁned because the right hand side is. Now it is easy to prove that Z is a group with respect to addition, and that 0 = [0, 0] is the neutral element. What does that mean? A group is a set G of elements together with a composition, that is, a map + : G × G −→ G that maps a pair of elements (g, g′) ∈ G × G to another element g + g′ ∈ G; we also demand that this composition satisfy the following rules: G1 there is a neutral element 0 ∈ G such that g + 0 = g for all g ∈ G; G2 for every g ∈ G there is an element g′ ∈ G such that g + g′ = 0 (we shall write g′ = −g); G3 the composition is associative: we have (g + g′) + g′′ = g + (g′ + g′′) for all g, g′, g′′ ∈ G. If the group also satisﬁes the condition G4 g + g′ = g′ + g for all g, g′ ∈ G; then we say that G is commutative (abelian). The set N of natural numbers is not a group with respect to +: there is a composition + : N × N −→ N, but the element 1 ∈ N has no inverse. In fact, if n + 1 = 0 were solvable in N, then 0 would be the successor of n in contradiction to Peano’s axiom N3. The set Z of integers, on the other hand, is a group with respect to +. In fact, Z is not only a group, it also carries the structure of a ring. But in order to see this, we have to deﬁne multiplication in Z ﬁrst. 17 2.3 Multiplication In order to deﬁne multiplication on Z, let us think of [r, s] as the ‘integer’ r − s; then we want [r, s] ⊙ [t, u] ≃ (r − s)(t − u) = rt + su − ru − st ≃ [rt + su, ru + st], and this suggests the deﬁnition [r, s] ⊙ [t, u] = [rt + su, ru + st]. (2.4) Once more we have to show that the multiplication (2.4) is well deﬁned and that it agrees with multiplication in N (actually we have deﬁned it in such a way that it must; what we have to check here is that ι(m) ⊙ ι(n) = ι(mn)). Then one generalizes distributivity, commutativity, associativity and the cancellation law to integers in Z. Let us just note in passing that (−1) · (−1) = [0, 1] ⊙ [0, 1] by our identiﬁcation = [1, 0] by (2.4) = +1 since ι(1) = [2, 1] More generally, for m, n ∈ Z we now can prove that (−m) · n = −mn, m · (−n) = −mn, (−m) · (−n) = mn. Thus the rules for multiplying signs come out naturally from our deﬁnition of multiplication on Z. Now we are ready to state that Z is a ring. A ring R is a set on which two kinds of compositions are deﬁned; they are usually denoted by + (addition) and · (multiplication). Of course, these compositions are to satisfy certain conditions; ﬁrst of all, r+s and r·s should be elements of R whenever r and s are. Moreover, we demand R1 R is an abelian group with respect to +; R2 (associativity): r(st) = (rs)t for r, s, t ∈ R; R3 (distributivity): we have r(s + t) = rs + rt and (r + s)t = rt + st for r, s, t ∈ R. R4 R contains a unit element e ̸= 0 satisfying er = re = r for all r ∈ R; The element e in R4 is usually denoted by 1. Note that every ring has at least two elements since 1 ̸= 0 by R4. If R also satisﬁes rs = sr for all r, s ∈ R, then we say that R is commutative. Finally, a ring R is called an integral domain if xy = 0 implies x = 0 or y = 0. In any ring we have 0x = 0: in fact, 0x = (0 + 0)x since 0 neutral element of + = 0x + 0x by distributivity, so substracting 0x from both sides gives 0 = 0x. 18 Theorem 2.2. The integers Z form a commutative integral domain with respect to addition and multiplication. Let us prove that Z is indeed an integral domain. Assume that xy = 0 for x, y ∈ Z. Write x = [r, s] and y = [t, u]. Then [0, 0] = 0 = xy = [r, s] ⊙ [t, u] = [rt + su, ru + st] by assumption, hence rt + su = ru + st. Now assume that x ̸= 0; then r + m = s or r = s + m for some m ∈ N by the Trichotomy Law for Addition. In the ﬁrst case, r + m = s for some m ∈ N. Then rt + (r + m)u = rt + su = ru + st = ru + (r + m)t, hence mu = mt and so u = t, that is, y = 0. The case r > s is treated similarly. 2.4 Z as an ordered domain Last not least we have to extend the relation < to Z. We put [r, s] < [t, u] if r + u < t + s. (2.5) This is well deﬁned and agrees with the ordering on N. For showing that the relation is well deﬁned, we have to assume that (r, s) ∼ (r′, s′) and (t, u) ∼ (t′, u′), and then show that r+u < t+s implies r′+u′ < t ′+s ′. For showing that the order just deﬁned agrees with the one we know from N we have to prove that n < m if and only if ι(n) < ι(m). Proposition 2.3. The set Z is simply ordered with respect to <. An ordered domain is a domain R together with an order < such that OD1 R is simply ordered with respect to <. OD2 If x < y, then x + z < y + z for x, y, z ∈ R. OD3 If x < y and 0 < z, then xz < yz. Proposition 2.4. Z is an ordered domain with respect to <. Proof. Write x = [r, s] and y = [t, u]. If z ∈ N, then we may put z = [v, 0]. By deﬁnition, x < y means r + u < t + s, and xz < yz is equivalent to (r + u)v < (t + s)v. Since v ∈ N, this is clear. The rest is left as an exercise. Proposition 2.5. In any ordered domain R, the following assertions are true: 1. If x < 0, then −x > 0. 2. If x < y and z < 0, then xz > yz. 3. We have x 2 ≥ 0 for all x ∈ R, with equality if and only if x = 0. Proof. 1. If x < 0, then x + (−x) < 0 + (−x) by OD2, and so 0 < −x. 2. We have 0 < −z, hence −xz = x · (−x) < y · (−z) = −yz, hence xz > yz. 19 3. If x ≥ 0, then multiplying through by x ≥ 0 gives x 2 ≥= 0; if x ≤ 0, then multiplying through by x ≤ 0 gives x 2 ≥ 0. We now introduce absolute values in any ordered domain by putting |x| = { x if x ≥ 0, −x if x < 0. Here are a few simple properties of absolute values: Lemma 2.6. In any ordered domain R, the absolute value | · | has the following properties. 1. |x| ≥ 0. 2. |xy| = |x| · |y|. 3. If s ≥ 0 and −s ≤ r ≤ s, then |r| ≤ s. Proof. 1. is clear if x ≥ 0; if x < 0, multiply through by −1 < 0. 2. Just consider the four possible cases: a) if x > 0, y > 0, then xy > 0, so the claim is xy = xy, which obviously holds; b) if x > 0 and y < 0, then xy < 0, hence the claim is −xy = x · (−y). The other two cases are treated similarly. 3. In fact, it is suﬃcient to prove that r ≤ s and −r ≤ s. The ﬁrst one is true by assumption, the second one follows from multiplying −s ≤ r through by −1. The following inequality is important: Proposition 2.7 (Triangle Inequality). For all x, y in an ordered domain, we have |x + y| ≤ |x| + |y|. Proof. By adding −|x| ≤ x ≤ |x| and −|y| ≤ y ≤ |y| we obtain −(|x| + |y|) ≤ x + y ≤ |x| + |y|. Now apply Lemma 2.6.3 to r = x + y and s = |x| + |y|. Division with Remainder The following property of the integers is the basis for the arithmetic of Z: Theorem 2.8. For every pair a, b ∈ Z with b > 0, there exist unique integers q, r ∈ Z such that a = bq + r and 0 ≤ r < b. Proof. The proof that q and r are unique is the same as in the proof of the analogous result in N. This result also takes care of the existence of q and r if a ≥ 0. Assume therefore that a < 0; then there exist q′, r′ such that −a = bq′+r′ with 0 ≤ r′ < b. Thus a = b(−q′) + (−r′), and we may take q = −q′, r = −r′ if r′ = 0, and q = −q′ − 1 and r = −r′ + b if r′ < 0. 20 2.5 Historical Remarks Already Diophantus had discovered rules like (a − b)(c − d) = ac − bc − ad + bd for positive rational numbers a > b and c > d, but his books do not contain any negative numbers. Negative numbers were, just as 0, invented by the Hindus (around 600 AD or earlier) and the Chinese (before 1100 AD). Although their positional system found its way into the Arabic world, negative numbers did not: they were not accepted as valid solutions by the Arabs. Leonardo di Pisa (also known by his nickname Fibonacci, which he was given by a mathematician of the 19th century, and which stuck), son of a merchant travelling around the Mediterranean, made Arabic numbers known in Europe; his books even contain some negative numbers (which are interpreted as debt), but they were not ac- cepted as useful. Thus when Italian mathematicians discovered the solution of the cubic, they treated x 3 + 3x + 1 = and x 3 + 3x = 1 etc. as being diﬀerent kind of cubics, and therefore had to distinguish a lot of cases. After Fermat and Descartes had started analytic geometry, negative numbers became ‘visible’ as solutions e.g. to quadratic equations that simply were to the left of the y-axis, yet negative solutions were called ‘false solutions’. Newton was one of the ﬁrst who used negative numbers freely in analytic geometry. Here are some bits and pieces from the history of negative numbers: • Nicolas Chuquet (1445–1488) wrote Triparty en la science des nombres, in which he worked with equations having negative numbers as coeﬃcients; this book was, however, lost for a long time and was published only in 1880. • Michael Stifel’s (1487–1567) book arithmetica integra explains how to work with negative numbers, which he calls ‘numeri absurdi’ or ‘numeri ﬁcti infra nihil’. • Cardano allows negative numbers as solutions if they can be interpreted as debt. In his theory of cubics, he does not allow negative coeﬃcients. • Simon Stevin (1548–1620) accepts negative numbers. • Ren´e Descartes (1596–1650) called negative solutions of polynomial equa- tions false roots. • Thomas Harriot (1560–1621) claimed that equations do not have nega- tive solutions; rather the negative solutions of f (x) = 0 are the positive solutions of f (−x) = 0. • John Wallis claimed that negatives do not exist, but that they are useful to work with. • Leibniz stumbled over the following problem in 1712: he observed that 1 −1 = −1 1 and claimed that this shows that −1 < 0 is false; otherwise the numerator on the left is bigger than the denominator, on the right it’s the other way round, yet the two fractions are equal. 21 • Auguste de Morgan in 1831: It is astonishing that the human intellect should ever have tol- erated such an absurdity as the idea of a quantity less than nothing, above all, that the notion should have outlived the be- lief in judicial astronomy and the existence of witches, either of which is ten thousand times more probable. Here’s another one: The imaginary expression √−a and the negative expression −b, have this resemblance, that either of them occurring as the so- lution of a problem indicates some inconsistency or absurdity. As far as real meaning is concerned, both are imaginary, since 0 − a is as inconceivable as √−a. His father-in-law William Frend had this to say about negative numbers in 1796: (A number) submits to be taken away from a number greater than itself, but to take it away from a number less than itself is ridiculous. Yet this is attempted by algebraists who talk of a number less than nothing; of multiplying a negative number into a negative number and thus producing a positive number; of a number being imaginary. . . . This is all jargon, at which common sense recoils; but, from its having been once adopted, like many other ﬁgments, it ﬁnds the most strenuous supporters among those who love to take things upon trust and hate the colour of serious thought. Exercises 2.1 Show that [r, s] ∗ [t, u] = [rt, su] is not well deﬁned on Z. 2.2 Prove the following rules for n, m ∈ Z: 1. −(n + m) = −n − m; 2. −(n − m) = m − n; 3. −(−n) = n. 2.3 Show that if a < b and c < d, then a + c < b + d. 22","libVersion":"0.3.1","langs":""}