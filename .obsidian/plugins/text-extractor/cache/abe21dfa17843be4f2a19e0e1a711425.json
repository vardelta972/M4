{"path":"iCloudDrive/bks/Combinatorics/Combinatorics/Combinatorics.pdf","text":"Combinatorics: Foundations to Olympiads Jacob Steinhardt 1 Combinatorics is the olympiad topic with possibly the least theory, but that doesn’t mean that it is easy. On the contrary, since it is not very conceptual, almost every olympiad combinatorics problem requires some degree of cleverness, and a good deal of experience. This lecture is meant to be only an introduction and a guide to the correct thought process and techniques. To truly gain a grasp of combinatorics requires signiﬁcant outside practice. 1 Techniques The following is a list of techniques in roughly the order I would personally consider them when approaching a problem: 1. Standard Counting 2. Pigeonhole 3. Simple Bijection 4. Simple Parity 5. Induction/Recursion 6. Contradiction/Well-Ordering 7. Simple Invariant/Monovariant 8. Generating Function 9. Intermediate Parity 10. Intermediate Bijection 11. Intermediate Invariant/Monovariant 12. Diﬃcult If you get all the way up to diﬃcult and still haven’t solved the problem, the technique you use should be completely on a problem-by-problem basis, as you most likely won’t have enough time to try more than one technique that falls under “Diﬃcult.” Of course, this order should not be taken as a strict rule, but rather a guide, and for some problems discarded completely, such as algebraic combinatorics problems, in which generating functions and other more algebraic techniques should be near the top of the list. Also note that in most cases multiple techniques will have to be brought together to solve a problem. 1Thanks to Haitao Mao and Daniel Schafer for contributions, as well as all of the instructors at MOP. 1 2 Standard Counting, Bijections, and Generating Functions Standard counting sounds exactly like what it is. All of your knowledge of AIME combinatorics will generally help you here, although counting in Olympiad problems may be signiﬁcantly more diﬃcult. We begin with three deﬁnitions: 1. The Principle of Inclusion-Exclusion (often abbreviated PIE) states, in its most useful form, that the number of ways to do something exactly once is the number of ways to do it at least once, minus the number of ways to do it at least twice, plus the number of ways to do it at least three times, etc. A more formal and general, but less intuitive statement, is that for sets S1, . . . , Sn, S1 ∪ . . . ∪ Sn = ∑ i Si − ∑ i<j Si ∩ Sj + ∑ i<j<k Si ∩ Sj ∩ Sk − . . . 2. The probability of an event occurring is the number of ways that event can occur divided by the total number of events that can occur. Now let P (A) denote the probability of A, and ¯A denote an event other than A. Then P (A)+P ( ¯A) = 1, and 0 ≤ P (A) ≤ 1. Let A∩B denote an event consisting of both A and B occuring, and let A∪B denote an event consisting of either A or B occuring. Then P (A ∩ B) = P (A)P (B), and P (A ∪ B) = 1 − (1 − P (A))(1 − P (B)) (note that this second formula follows directly from the ﬁrst formula combined with the Principle of Inclusion-Exclusion). 3. The average value or expected value of a quantity is the sum of its values over all applica- ble cases, divided by the number of cases. Conversely, the total quantity of something over all possible cases is the average value times the number of cases, which can be useful especially in symmetric situations. In addition, average and expected value (more often the latter) can be taken to mean a weighted average based on the “value” of several related events and their respective probabilities of occuring. Here are a few tips: 1. Overcounting/undercounting can be useful, especially when proving a bound. 2. Sometimes “obvious” observations can be key to solving a problem, so don’t discard them. 3. Oftentimes it is easier to count the converse. 4. Don’t be afraid to use PIE (Principle of Inclusion/Exclusion). 5. Don’t be afraid to try small examples. 6. Try to make it easier to count what you are trying to count (i.e. rephrase the problem into an equivalent, but nicer, form). 7. Find the average value, then multiply by the number of elements. 2, 5, and 6 are also applicable to problems in general (even problems that aren’t combinatorial in nature). A Bijection involves drawing a one-to-one correlation between two quantities, thus showing that the two quantities are in fact equal in magnitude. Once you have familiarized yourself with a 2 problem, often some bijections/potential bijections become obvious if you are thinking about using a Bijection (which is why it is good to speciﬁcally consider them, as well as “special” techniques in general). It is worth taking the time to see whether any of them are helpful. However, other bijections can be considerably more diﬃcult. You will want to try other tech- niques ﬁrst, but if you have decided to look for a more complicated bijection, my suggestion is to try diﬀerent possible mappings and try to disprove them, then if you can’t, try to prove that they work. If it seems too diﬃcult to prove that a bijection works it might be good to try a diﬀerent bijection instead. Generating functions warrant their own lecture. However, the idea is to encode combinatorial information into an algebraic system, more speciﬁcally the coeﬃcients in a power series. The easi- est way to become familiar is with examples. The main idea to keep in mind is that if two quantities are algebraically equal, then the coeﬃcients in their power series expansions are also always equal, as are their roots, etc. Here is a quick review of how to count2: 1. Prove that one can arrange a set of n items in n! ways. You can place the ﬁrst element in any of n places. You can place the second element in any of n − 1 places. You can place the kth element in any of n − k + 1 places. Thus there are a total of n · (n − 1) · (n − 2) · . . . · 3 · 2 · 1 = n! possibilities. 2. Prove that one can choose k out of n items (order does matter) in n! (n − k)! ways. Use the same argument as before, except stop just before the k + 1st element. Then you get n · (n − 1) · (n − 2) · . . . · (n − k + 1) = n! (n−k)! possibilities. 3. Prove that one can choose k out of n items (order doesn’t matter) in n! k!(n − k)! ways. This is the deﬁnition of combination, so it is clearly (n k) = n! k!(n−k)! . This can be easily derived; there are n choices for the ﬁrst item, (n − 1) for the second, until eventually there are (n − (k − 1)) for the kth. However, there are k! orderings of these k items, so there must be n(n−1)···(n−k+1) k! = n! k!(n−k)! total combinations. 4. Prove that (n k) sequences a1, a2, . . . , ak of positive integers exists such that ai < ai+1 ≤ n. Clearly, each of the ai is distinct. Also, given any k distinct numbers, there will be exactly 1 sequence of ai with those k numbers in it that satisﬁes the requirement. This creates a bijection between sequences a1, . . . , ak and sets of k numbers chosen from the numbers 1,2,. . . ,n. The number of sets for the latter is clearly (n k), so there are (n k) such sequences. 5. Prove that n distinct items can be partitioned into k groups in nk ways. Consider each item individually. For each item, there are k options of what group to put it in. There are n such choices, each of which is independent, so there are nk ways to perform the partition. 6. Prove that one can travel from (0, 0) to (x, y) traveling only to the right and up and only between adjacent lattice points in (x+y x ) ways. 2Thanks to Daniel Schafer, the co-author of this section. 3 Consider representing each path with a list of what direction was travelled, either right (R) or up (U). Clearly, any path can be represented by a distinct arrangement of the sequence RR · · · RU U · · · U , where there are x Rs and y U s. This creates a bijection, so the number of paths is the same as the number of arrangements, which is (x+y x ). 7. Prove that n distinct items can be partitioned into k groups of sizes s1, s2, . . . , sk, where s1 + . . . + sk = n, in n! s1!s2! · · · sk! ways. Consider selecting each group seperately. For the ﬁrst group, there are ( n s1) options, for the sec- ond, (n−s1 s2 ), etc. Multiplying these out, there is a total of ( n s1)(n−s1 s2 )(n−s1−s2 s3 ) · · · = n! s1!s2!···sk! . This value is often expressed as ( n s1,s2,...,sk) = n! s1!s2!···sk! , and is refered to as a multinomial coeﬃcient. Note that these coeﬃcients have a relationship with the term a s1 1 · · · a sk k in the ex- pansion of (a1 + . . . + ak)n similar to that of binomial coeﬃcients in the expansion of (x + y)n. Also note that if s1 + . . . + sk < n, one can add a pseudo-set sk+1 which contains all of the items not in any of the ﬁrst k sets (so its size will be n − (s1 + . . . + sk)), and calculate the coeﬃcient from there. Note that this value is also the number of ways to arrange n objects in k indistinct groups of sizes s1, s2, . . . , sk, where the sizes again sum to n. 8. Prove that (n+1 k+1) = (n k) + ( n k+1). Method one. Writing out the factorial notation and simplifying quickly yields the desired reuslt. n! k!(n−k)! + n! (k+1)!(n−k−1)! = n!(k+1) (k+1)!(n−k)! + n!(n−k) (k+1)!(n−k)! = n!(n+1) (k+1)!(n−k)! = (n+1 k+1). This is the basis of Pascal’s Triangle. Method two. Consider selecting k + 1 items from n + 1. Either the ﬁrst item is chosen, in which case there are (n k) ways to select the remaining k, or the ﬁrst item is not chosen, in which case there are ( n k+1) ways to choose the remaining k + 1. Thus, (n+1 k+1) = (n k) + ( n k+1). 9. Prove that 2n = (n 0) + (n 1) + . . . + ( n n−1) + (n n ). This can be derived easily by counting in two ways. This is the total number of subsets of a set of size n; for each element of the original set, there are two options: in the set, or not in the set. Thus, there are 2n subsets, and the expression above simpliﬁes to 2n. 10. Prove that (n−1 k−1) positive integer solutions exist to the system a1 + a2 + . . . + ak = n. Draw n circles in a row, and consider drawing k − 1 lines in the n − 1 gaps between the circles. Let a1 be the number of circles before the ﬁrst line, a2 be the number of circles between the ﬁrst and second lines, etc. Clearly, there will be k total ai (if there are k − 1 lines), all ai will be at least 1 (since there is at least 1 circle between each gap) and the sum of the ai will be n (since each circle is counted exactly once). Thus, there is a bijection between the sequence a1, . . . , ak and the drawing; as the drawing was generated by choosing k − 1 lines from n − 1 gaps, there are (n−1 k−1) drawings, and thus (n−1 k−1) sequences. This algorithm is sometimes refered to as “Stars and Bars.” 11. Prove that (n+k−1 k−1 ) non-negative integer solutions exist to the system a1 + a2 + . . . + ak = n. Draw n + k − 1 circles in a row, and cross out k − 1 of them. Let a1 be the number of circles before the ﬁrst crossed-out one, a2 be the number of circles between the ﬁrst crossed-out one and the second crossed-out one, etc. Clearly, there will be k total ai (if there are k − 1 crossed out circles), all ai will be at least 0 (since there may be two consecutive crossed-out circles) and the sum of the ai will be n (since each remaining circle is counted exactly once, and there are (n + k − 1) − (k − 1) = n remaining circles). Thus, there is a bijection between the 4 sequence a1, . . . , ak and the drawing; as the drawing was generated by choosing k − 1 circles from n + k − 1 choices, there are (n+k−1 k−1 ) drawings, and thus (n+k−1 k−1 ) sequences. Note that this algorithm can be used to determine the number of ways to partition n indistinct objects into k sets. 12. Prove that (n−km−1 k−1 ) integer solutions exist to the system a1 + a2 + . . . + ak = n if ai > m. Method one. Use algebraic manipulation. Subtract km from both sides, so that now we have b1 + b2 + . . . + bk = n − km with bi > 0 (we subtracted m from each of the ai’s). Now apply the previous argument and arrive at (n−km−1 k−1 ). Method two. Use a bijection. This is the same as dividing up a set of size n into k groups, all of size greater than m. But this means we can remove m items from each group and still have a positive number of items in each group, yielding a scenario in which we divide up the set of size n − km into k non-empy groups. Also, for every scenario with this smaller set we can add m items to each group to get back to what we had in the larger set. This means there is a one-to-one correspondence between the number of possibilities in both cases. We count the easier quantity (the set of size n − km). To ensure that all sets are non-empty, we simply place k − 1 dividing lines between elements of the set to divide the set into k subsets. There are (n−km−1 k−1 ) ways to do this, as there are n − km − 1 spaces between successive elements of the set. 13. Prove that one can arrange n of one object and k of another in (n+1 k ) ways if none of the k objects may be next to each other. First, lay out the ﬁrst objects in a row of length n. There are now n + 1 gaps to place the k other objects in (there are n − 1 gaps between the layed-out objects and 1 on both ends of the row). Thus, there are (n+1 k ) arrangements of these objects to avoid having any of the k objects touch each other. 14. Prove that one can place k indistinct items between n other indistinct items in (n+k−2 k ) ways. (Any number of the ﬁrst type can go between the sucessive items of the second type). Draw n + k circles in a row, and mark k of them as objects of the second type. Clearly, one cannot mark either the ﬁrst or the last, as the problem speciﬁes that the second objects go between objects of the ﬁrst type. Thus, there are n + k − 2 markable objects, and k marks, so there are (n+k−2 k ) arrangements. 15. Prove that (n+k+1 n+1 ) = (n n ) + (n+1 n ) + . . . + (n+k n ). Note that if we have a set of size n + k + 1 and we wish to choose n + 1 elements, the ﬁrst element we choose from the set can be either the ﬁrst, second, third, etc., all the way up to the k +1st element. Each of these corresponds to one of the elements in the sum (in general, if the ﬁrst element we choose is the ith element in the set, then there are n + k + 1 − i elements in the set left to choose from, and there are n elements left to choose, yielding (n+k+1−i n ) choices). Thus, the sum is equal to (n+k+1 n+1 ), as desired (this is known as the Hockeystick Identity). 16. Prove that: 1 = (n 0 ) 5 n∑ i=1 1 = (n 1 ) n−1∑ i=1 n∑ j=i+1 1 = (n 2 ) n−2∑ i=1 n−1∑ j=i+1 n∑ k=j+1 1 = (n 3 ) and so on. This is a direct result of repeatedly applying the Hockeystick Identity. 17. Prove that: ∑ a+b=k (n a )(m b ) = (m + n k ) The right-hand side is clearly the number of ways to pick k elements from an m+n element set. Now consider splitting the set into two sets, one of size n and the other of size m, and picking a total of k elements between the two sets. This is of course equivalent to picking k elements from the original set, so it is equal to the right-hand side, but it is also the left-hand side of the equation, thus the above identity. Alternately, note that (x + 1)m(x + 1)n = (x + 1)m+n, thus the coeﬃcient of xk is equal in both, yielding the above identity. 18. Prove that the nth Catalan number Cn = ( 2n n ) n+1 satisﬁes the recursion Cn = ∑ a+b=n−1 CaCb. We conjure up the following problem, which we will then show obeys both the Catalan for- mula and its recursion: In an n x n grid, how many paths between adjacent lattice points, going only to the right and up, start at the bottom-left and end at the top-right, and never cross the main diagonal? Let p(n) denote the number of such paths. The main diagonal can ﬁrst be touched after 2, 4, . . . , 2i, . . . , 2n moves, splitting the problem up into identical subproblems of size i and n − i − 1, so that the desired recursion is satisﬁed. Now consider the paths that do cross the diagonal. We draw a bijection between these paths and paths in an (n − 1) x (n + 1) grid going only to the right and up, and starting in the bottom-left and going to the top right, as follows: immediately after a path crosses the diagonal, reverse the direction of all moves after that in the path. For the reverse mapping, draw a diagonal in the (n − 1) x (n + 1) grid from the point (0, 0) to (n − 1, n − 1). All paths ending in the top-right must cross this diagonal at least once. Take the ﬁrst such time that this happens, and reverse the direction of all moves after that move in the path. We now have the desired bijection. The number of paths in the (n − 1) x (n + 1) grid is ( 2n n−1), which is also the number of 6 paths that do cross the diagonal in our original grid. There are (2n n ) total paths, regardless of whether they cross the diagonal or not, so subtracting out, we get (2n n ) − ( 2n n−1) = ( 2n n ) n+1 , as desired. 19. Prove that the number of paths of length n that can be made using only left or right moves of length 1, starting on the left side of a line segment of length n, is ( n ⌊ n 2 ⌋). Consider the number of ways one can return to the origin with a path of length 2n (note that there is clearly no way to return to the origin with a path of length 2n + 1); let this value be g(n). Clearly, the ﬁrst move and the last move are preordained; the ﬁrst move is invariably a move to the right and the last move a move to the left. Thus, if the path never returns to the origin until the last move, there are g(n − 1) options. If the path returns on the second move, then there are g(n − 2) options; on the fourth move, g(1)g(n − 3), etc. Thus, there are g(n) = g(n−1)+g(n−2)+g(1)g(n−3)+g(2)g(n−4)+. . .+g(n−4)g(2)+g(n−2)g(1)+g(n−2)+g(n−1) options. This is the recurrence for the Catalan numbers as shown above, so g(n) is the nth Catalan number, which is (2n)! (n)!(n+1)! . Now, consider f (n) to be the number of paths possible after n moves (without the return to the origin restriction placed on g.) A recurrance relation can be easily found; any path of length x − 1 that does not end at the origin has two child paths of length x, and any path of length x − 1 that does end at the origin has one child path of length x. Thus, for even numbers (2n + 2), the recurrance is f (2n + 2) = 2f (2n + 1), as no odd path can end at the origin. For odd numbers (2n + 1), the recurrance is f (2n + 1) = 2f (2n) − g(n). The proof will be completed through induction. Assume the solution is f (n) = ( n ⌊ n 2 ⌋). The base cases are n = 1 → f (n) = 1 and n = 2 → f (n) = 2, so the base case is complete. For any odd number 2n + 1, f (2n + 1) = 2f (2n) − g(n). Testing this, 2f (2n) − g(n) = 2( 2n ⌊ 2n 2 ⌋) − 1 n+1 (2n n ) = 2 (2n n ) − 1 n+1 (2n n ) = (2n n )(2 − 1 n+1 ) = (2n n )( 2n+1 n+1 ) = (2n+1 n+1 ) = (2n+1 n ) = f (2n + 1), so the induction works for all 2n+1. For any even number 2n+2, f (2n+2) = 2f (2n+1). Testing this in the induction, 2f (2n+1) = 2( 2n+1 ⌊ 2n+1 2 ⌋) = 2 (2n+1 n ) = (2n+1 n )+(2n+1 n+1 ) = (2n+2 n+1 ) = f (2n+2), so the induction works for all 2n+2. Thus, the induction is complete, and ( n ⌊ n 2 ⌋) is the number of paths possible. 20. Prove that one can place in order a total of n elements of two diﬀerent types in ( n ⌊ n 2 ⌋) ways if one can at no point have placed down more elements of the ﬁrst type than of the second type. If one considers placing items of the second type moves to the right and items of the ﬁrst type moves to the left, there is a clear bijection to the scenario of the previous problem. 3 Pigeonhole The Pigeonhole Principle comes in two forms, both of which may seem obvious, but which can often be crucial in even the most diﬃcult problems. Form 1: Discrete Pigeonhole - If n objects are partitioned into k disjoint sets, then at least one set must have at least ⌈ n k ⌉ objects and at least one set must have at most ⌊ n k ⌋ objects. Form 2: Continuous Pigeonhole - Objects with a total length/area/volume of X cannot be packed into a space with length/area/volume less than X without overlap. 7 A nice thing about these is that they provide an extremely easy upper/lower bound to most problems, and can usually give insight into the problem itself. These two reasons are why Pigeon- hole is so early on the list. However, some problems involving Pigeonhole can be extremely clever (sometimes the Pigeonhole itself is clever, more often the Pigeonhole ﬁnishes a more complicated proof). 4 Parity The idea behind parity is to show that two things are diﬀerent (or, oftentimes, to show that some- thing is diﬀerent from itself, thus ﬁnding a contradiction) by showing that they are diﬀerent modulo some natural number, most often 2, and sometimes 3 or maybe even 4. Larger cases are extremely rare, except in the case when things are taken modulo n, where you are trying to prove something in terms of n (or modulo 2006, 2007, etc.). A good example to keep in mind is that the sum of the degrees in a graph is even (this is a consequent of the fact that every edge increases the sum by 2, as it connects two vertices). 5 Induction/Recursion Recursion is another topic that really warrants its own lecture. I have provided 18 recursion prob- lems at the end of this section for anyone wishing to practice (which I would highly recommend doing). However, as with Bijections, Recursion is a technique that is much easier to spot when you are speciﬁcally looking for it. I have heard many people comment on some rather imposing prob- lems, saying that they are much easier if you know to try recursion. The easiest way to “know” to try recursion, or any technique for that matter, is to simply always try it if it seems reasonable! A word of warning, though, is not to get stuck on a technique once you have tried it. Unless it seems promising, move on to something else. It is hard to strike a good balance betwen trying diﬀerent techniques and pursuing a single technique through to its completion, but you will eventually ﬁnd it with suﬃcient practice. Sometimes you will ﬁnd a recursion that goes back to itself in the recursive step. (Say f (n) = af (n) + bf (n − 1) + 1). In this case the easiest thing to do is to move all instances of f (n) to the left-hand side and divide by their coeﬃcient. (In our example, take (1 − a)f (n) = bf (n − 1) + 1, f (n) = bf (n−1)+1 1−a ). Another possible way to solve this recursion is to continually expand out the recursion on the right-hand side to obtain an inﬁnite geometric series, but this is almost invariably harder, and can lead to problems of convergence as well. Also, given any linear recurrence relation, that is, a recursion of the form fn = a1fn−1 + . . . + akfn−k an explicit formula for fn can be obtained and will be of the form fn = b1rn 1 + . . . + bkrn k where r1, . . . , rk are the roots of the polynomial obtained by solving x k = a1x k−1 + . . . + ak 8 and b1, . . . , bk are determined by the ﬁrst k terms in the recursion and can be obtained by solving the system: b1ri 1 + . . . + bkri k = fi and so on for some k values of i where fi is known (usually i = 0, . . . , k − 1 or i = 1, . . . , k). This all assumes that the roots are distinct. If the roots are not distinct, the only thing that is worth knowing is that in the two variable case, the explicit formula becomes fn = b1rn + nb2rn In addition, if a polynomial P (n) is tacked on at the end of the recurrence, i.e. the recurrence is in the form fn = a1fn−1 + . . . + akfn−k + P (n) Then you can subtract consecutive values of fn from each other to kill the leading coeﬃcient and then obtain a new recurrence formula for fn in which k has increased by one, but in which the degree of P (n) has decreased. You can continue this process until P (n) vanishes, thus reducing the problem to the previous case, which we already know how to solve. Here are two examples: Example one: Find an explicit formula for the sequence satisfying f0 = 0, f1 = 1, fn = fn−1+fn−2. Solution: Solving x2 = x + 1, we get x = 1+√5 2 , 1−√5 2 (call these ϕ and ¯ϕ, so that our for- mula must be of the form fn = b1ϕn + b2 ¯ϕn. Solving the system b1 + b2 = 0,ϕb1 + ¯ϕb2 = 1, we obtain b1 = 1 ϕ − ¯ϕ , b2 = 1 ¯ϕ − ϕ , leading to an explicit formula of fn = ϕn − ¯ϕn ϕ − ¯ϕ (this is the explicit formula for the Fibonacci sequence, and also proves that the ratio of successive terms does indeed converge to the Golden Ratio). Example two: Find an explicit formula for the sequence satisfying f0 = k, fn = 2fn−1 + 1. Solution: Subtracting fn−1 from fn, we obtain fn − fn−1 = 2fn−1 − 2fn−2, or fn = 3fn−1 − 2fn−2. Then solving x2 = 3x − 2, we obtain x = 1, 2, so fn = b12n + b2 for some b1, b2. We calculate f1 from the recurrence relation and see that f1 = 2f0 + 1 = 2k + 1. Then we solve the system b1 + b2 = k,2b1 + b2 = 2k + 1, and obtain b1 = k + 1, b2 = −1, so that fn = (k + 1)2n − 1. Whenever solving for an explicit formula for a linear recurrence, you should ﬁnd the formula as part of your scratchwork, then provide the formula and prove it by induction in your write-up. There are, in fact, four diﬀerent types of induction. There is normal induction, which is the type you learn in your precalculus class, where you assume that a statement is true for n = k − 1 and then prove it is true for n = k, thus showing that if it is true for some natural number m is it true for every natural number l > m. The second type is strong induction, in which you assume that a statement is true for every value of n, m ≤ n < k, and then show it is true for n = k. This is the type you would use to prove explicit formulas for recurrences as described above. There is recursive induction, in which you break up a problem recursively into smaller cases. Finally, there is prime induction, in which you show the statement is true for every prime and that is true for ab if it is true for a and b. I have listed the four in approximate order of sophistication and diﬃculty. 9 Induction is another technique that is good to keep in mind, and is again easier when speciﬁ- cally looking for it. However, I ﬁnd that the best way to use induction as a tool is to just always assume that the statement is true for the previous value of n (you don’t have to use the fact, just always know that you can assume it, so long as you can prove i t for the base case). It is also sometimes good to prove the “base case” of a problem - that is, the smallest case for which the problem is true (or maybe the smallest non-trivial case). This might give you insight on how to generalize the result, and at the very least has a chance of giving you a point of partial credit if it isn’t trivial (don’t count on that point, though). Also, induction will not work if the statement you are trying to prove is weaker for some values of n than for others (that is, stonger statements cannot be proven for any values of n, the statement is as strong as possible for all values). To get around this sometimes you prove a stronger statement and bring it into your inductive step. Recursion Practice: 1. (Traditional) Consider a 2-player game where each player takes turns removing between 1 and 7 stones. Whoever can’t remove a stone loses. There are 2006 stones and you go ﬁrst. How many stones do you remove in order to win? 2. (Mandelbrot 4 2006, 6) Two rows of ten pegs are lined up and adjacent pegs are spaced 1 unit apart. How many ways can ten rubber-bands be looped around the pegs so that no peg does not contain a rubber band? (Rubber bands cannot stretch more than √2 units.) 3. (MStueben) In how many ways can you make change for a quarter with pennies, nickels, and dimes? 4. (AIME I 2006, 11) You have 8 cubes of size 1 through 8. You must build a tower with the constraint that the cube on top of a cube of size k must have a size of at most k + 2. How many diﬀerent towers can be constructed? 5. (HMMT Guts) How many 10-bit binary strings can be made so that no three consecutive bits are the same? 6. (JSteinhardt) What is the sum of all such binary strings (a base-10 answer will be suﬃcient)? 7. (JSteinhardt) How many 8-bit trinary strings (0’s, 1’s, and 2’s) can be made so that no three consecutive bits are the same? 8. (JSteinhardt) I have seven bowls of varying sizes. I cannot put a larger bowl in a smaller bowl. How many possible arrangements of bowls can I make (multiple stacks are allowed)? 9. (JSteinhardt) Let S = {1, − 1 2 , 1 4 , − 1 8 , 1 16 , ... }. Let A = a1, a2, a3, a4, ..., a2005, a2006 | ai ∈ S. Let P (A) = 2006∏ i=1 ai. What is the sum of P (A) for all distinct A (order does matter)? 10. (MOP 2006) How many subsets of the set {1, 2, . . . , 2005} have a sum congruent to 2006 modulo 2048? 11. (MOP 2006) Link ﬁnds himself in a dungeon, with k small keys in his inventory and n locked chests in the dungeon. Each chest contains 1 rupee, and n − k of the chests also contain a small key. Each small key can only be used once. What is the expected number of rupees that Link will attain, in terms of n and k? 10 12. (Balkan? Math Olympiad) How many natural numbers less than 101997 have their digits in strictly non-decreasing order? 13. (Alex Anderson) How many integers 0 ≤ n < 1011 have a sum of digits divisible by 11? 14. (MOP 2006) Consider a convex n-gon with vertices P1, P2, . . . , Pn with all of its edges and diagonals drawn in. Each line between two vertices is assigned a number. Among any 3 vertices, the lines joining them have two numbers that are the same and one that is diﬀerent, and the diﬀerent one must be smaller than the other two. We wish to know two things: (i) What is the least number of distinct numbers that allow such a situation (in terms of n)? (ii) In how many ways can this minimal arrangement be achieved? 6 Contradiction/Well-ordering These techniques should be tried especially if you feel that there is “not enough” information in the problem, speciﬁcally because by assuming the contrary you add an entirely new piece of information that you can use. Contradiction is a slightly trickier mindset than induction, but the same general idea applies, in that you should know that you can always assume that a statement is false. Sometimes contradiction and induction will both be involved in a problem simultaneously (or multiple inductions). 7 Invariants/Monovariants The idea behind a monovariant is that if a process always decreases some quantity (or always de- creases it after a ﬁnite number of steps), and the quantity has a lower bound (usually zero), then the process can only occur a ﬁnite number of times. The same is true for a process that increases a quantity when the quantity has an upper bound. This is a somewhat sophisticated idea, but it is involved in many problems of the form “prove that this sequence is eventually constant” or “prove that this process eventually terminates”. The idea behind an invariant is to show that something remains the same or has the same parity, or is periodically constant, or to prove some sort of constancy to a process in question, and then to attack the problem with other methods, usually parity and contradiction and sometimes induction. 8 Examples with Thought Processes 1. (IMO 2002 Shortlist C1) Let n be a positive integer. Each point (x, y) in the plane, where x and y are non-negative integers with x + y < n, is colored red or blue, subject to the fol- lowing condition: if a point (x, y) is red, then so are all points (x′, y′ with x′ ≤ x and y′ ≤ y. Let A be the number of ways to choose n blue points with distinct x-coordinates, and let B be the number of ways to choose n blue points with distinct y-coordinates. Prove that A = B. The fact that we are trying to prove that two similar things are equal screams to us that a bijection is likely to be the solution. However, ﬁrst we should look at some small cases to (1) verify our understanding of the problem statement and (2) gain insight into the prob- lem itself. The x + y < n condition says that we are working within a triangle in the ﬁrst quadrant, and the second condition says that the red points form a stairstep pattern. An important-looking observation is that the distance to the boundary of the triangle on the right and above is always equal, which can be shown fairly easily by induction. 11 At this point a good question to ask is how we can count A or B. The answer is that it is the product of the number of blue points in each row or column. Doing some small cases shows that the result we are trying to prove is (probably) true. It also shows that the number of blue points in one row corresponds to the number of blue points in some other column (not necesarrily the one that would obviously correspond). Now a good question to ask is what the correspondence is. One way to try to ﬁgure this out is to draw one example, then change the pattern of red points slightly and see what changes. We might also see if our observation is of any use. In fact, our observation shows that at least one part of the correspondence is that if the point (x, y) is a red point on a “corner” of the staircase, then column x corresponds with row y. However, though this information is tempt- ing, it is hard to apply it to situations when we are not near a corner. We notice, however, that the changes are quite simple when we simply add in a new red point at a “niche” in the staircase (that is, where the staircase changes from going vertically to going horizontally). In fact, we can generate any staircase simply by adding points into these niches, provided that we already have lines of red points along the x and y axes of the proper length. This idea leads us to abandon for the moment the idea of a bijection and try induction, assuming that a correspondence can be drawn for some previous arrangement of red points and then induct- ing. First we induct to get points along the x and y axes, and then we induct adding points in at niches. Both of the inductive steps are fairly simple: in the case of the x and y axes, we use our observation that the new point we are adding is the same distance from the boundary of the triangle to the right and above, and our inductive step follows. For the case of niches, the same observation completes the inductive step. Each of the inductive steps is completed because we are decreasing the number of blue points in a row and column, both of which contained previously the same number of blue points, by one. We are assuming by induc- tion that a correspondence could be drawn between rows and columns before, so as we have redrawn the correspondence in the only thing we changed, the statement obviously still holds. Comment: In fact, there is a bijective solution to this problem, but the particular line of thought that I chose to follow lead away from it. Here is the bijection: start at a point just above the boundary of the staircase, then go diagonally up until you are just about to hit the staircase again, or to go out of the ﬁrst quadrant. The column of the ﬁrst point corresponds to the row of the second point, and you can reverse this by reﬂecting about the line y = x and applying the same mapping. The motivation of this bijection is, once again, the observation that we made, so it is actually not unreasonable to arrive at either of the above solutions, depending on individual style and also simply random chance. 2. (MOP 2006) Let M be a subset of the set S = {1, 2, . . . , n} with m ≥ 3 elements. Prove that there are sets A ⊆ M and B = {b, c} ∈ S such that A has at least m(m−1)(m−2) 3(n−1)(n−2) elements and for each element a in A, all three numbers a,a + b, and a + c belong to M . Especially when problem statements are somewhat long, it is good to rephrase them in a more intuitively understandable form. The idea is that given some subset of the ﬁrst n nat- ural numbers you pick two numbers and try to ﬁnd a set of the given size such that for each element in the set you pick, if you add one of the two numbers it’s still in M . Also, a nicer way to write the size of the set is ( m 3 ) ( n−1 2 ) , or, since the answer must be an integer, ⌈ ( m 3 ) ( n−1 2 ) ⌉. This form looks a lot like the end result of Pigeonhole, something that we might want to keep in mind. 12 However, before proceeding, it is good to try examples. From here it becomes clear that m = 3 is always true, as if you have M = {x, y, z} you pick B = {y − x, z − x} and A = {x}. Four is proven identically, with an example for the case n = m = 4 (the only point at which the size of A need be greater than 1). This doesn’t generalize very well, however, so we seek a case that is more interesting, when the size of the set need be greater than 1. One example is m = 6, n = 7. On trying the set M = {1, 2, 3, 5, 6, 7} I noticed that what I was looking for was two triples of numbers with the same pairwise diﬀerence. Here that would be (1, 2, 3) and (4, 5, 6). This diﬀerence can be either interpreted as 2 − 1 = 5 − 4 = 1, 3 − 2 = 6 − 5 = 1, or 4 − 1 = 5 − 2 = 6 − 3 = 3. This is a very promising interpretation of the problem. At this point we might try to use contradiction. The motivation for this is that it is much easier to eliminate all triples with the same pairwise diﬀerence and then show that the leftover set is too small than to try to attack the problem normally. Also, as we already have a proof for m = 3, we can assume that there is a set of size m − 1 with the properties we want. A reason why we suspect that an inductive statement might work is that the statement is basically uniformly strong for all values of m and n. However, currently is it unclear exactly what inductive step to use, as the size of the set increases weirdly, so we don’t pursue this avenue of attack yet. We will leave oﬀ on contradiction for the time being, as well, because it is unclear how to ﬁnd a bound on the size of A or M in the general case. As neither contradiction nor induction seem promising, though they could possibly be useful later, we return to Pigeonhole. First, though, we need to count a few things. There are (m 3 ) ways to pick a triple of numbers from M . This is a good sign, as it is one of the numbers involved in the problem. Where might this mysterious (n−1 2 ) come from? One idea is that it is the number of possible sets B. This is another good sign. Indeed, we are now done, because if we partition our (m 3 ) triples into sets based on the diﬀerence between the second and ﬁrst term and the third and second term, this corresponds directly to a possible choice of B, so by Pigeonhole at least one of the choices must work. Comment: It turned out that our ﬁrst idea, Pigeonhole, was the correct choice. However, at the time we were not sure how to use it, so we tried some examples and also considered some other techniques, all of which provided more insight into the problem. Note that in this and in the previous example, what I wrote is the thought process behind the solution and should not be included in the writeup of the problem. 9 Other Examples 1. (USAMO 1997/1) Let pn be the nth prime. Let 0 < a < 1 be a real. Deﬁne the sequence xn by x0 = a, xn = pn xn−1 − ⌊ pn xn−1 ⌋ if xn ̸= 0, or 0 if xn−1 = 0. Find all a for which the sequence is eventually zero. All rational numbers will eventually cause the sequence to be zero. Clearly any irrational value of a will result in a sequence which remains irrational, and, as zero is rational, can never become zero. Now suppose a is rational, and let xn = bn cn , with bn and cn relatively prime. We show that bn is monotonically decreasing, and that it therefore must eventually reach zero. Proof: Let {x} = x − ⌊x⌋ denote the fractional part of x. Then xn+1 = { pn+1 xn } = { pn+1cn bn } = 13 bn+1 cn+1 , but bn+1 < cn+1 ≤ bn, so bn is a monotonically decreasing sequence and we are done. Comment: The above proof is an example of how a monovariant can be used to prove that a sequence is eventually zero. As mentioned before, a monovariant is the natural choice for a problem such as this. The fact that all rational numbers work would be realized by ex- amples (remember, it is much easier to prove something when you know what you are trying to prove!). From here the correct monovariant can be deduced through examples, through looking at how the sequence changes algebraically, or just simply by guessing (which can, in fact, be a useful tool). Another important idea is expressing rational numbers in the form p q , where p and q are relatively prime (and in this case quickly eliminating the possibility of irrational numbers). 2. (MOP 2006) Let n be a positive integer. The integers 1, 2, . . . , n are written on a blackboard. Two numbers on the board, say a and b, are selected, erased, and the number |a−b| is written on the board. This process is repeated until there is just one number on the board. What are the possible values for this number? We wish to show that the possible values are those whose parity is the same as the sum modulo 2, and who are no greater than n. We ﬁrst show that this is necessary by introducing an invariant, the parity of the sum of the numbers. The parity of the sum does not change because |a − b| ≡ a − b ≡ a + b (mod 2). We now show by induction that all such values are possible. The base cases are trivial. Assuming the statement is true for n − 1 guarantees that we can get all values except 0 or 1. To get these values, pair n and n − 1, n − 2 and n − 3, etc. Then you have only 1’s, and from here it is easy to get down to either 0 or 1. Therefore we have our inductive step and we are done. Comment: The answer itself would have been deduced through trying some examples. Once one ﬁnds that the answer is that the ﬁnal number must have the same parity as the sum, it is natural to show that the sum is invariant modulo 2 because, if it is true, it would be very easy to show (note that all we had to do was take it mod 2, and the invariant fell out immediately). Induction is also natural because we are trying to show that it is possible to attain an entire group of numbers, so it would be diﬃcult to provide any sort of algorithm to ﬁnd them. However, induction immediately kills oﬀ all but one of the numbers, making it a fortuitous choice. 3. (MOP 2006) Let n be an integer greater than 1, and let A be a set of real numbers with less than n elements. Suppose that 20, 21, ..., 2n−1 can be written as the sum of distinct elements in A. Prove that A contains at least one negative number. WLOG we can put the set in increasing order. We will assume the contrary and then use strong induction. Our inductive hypothesis is that if A = {a1, a2, . . . , am}, then ai ≤ 2i−1. For the base case, a1 ≤ 20 or 20 could not be written as the sum of distinct elements in A. For the inductive step, we can assume that a1 + . . . + ak−1 ≤ 20 + . . . + 2k−2 = 2k−1 − 1 < 2k−1, so ak ≤ 2k−1 or 2k−1 could not be written as the sum of distinct elements in A. Then a1 + . . . + am ≤ 20 + . . . + 2n−2 = 2n−1 − 1 < 2n−1, so 2n−1 cannot be written as the sum of distinct elements in A, we have contradiction, and we are done. 14 Comment: When given a set there is almost no reason not to sort its elements unless the problem forces you to do otherwise. Sorting makes dealing with the set much easier conceptually, and here it practically gave the answer. It is also natural to try contradiction, because otherwise there is practically nothing to work with. Once the set is sorted and we are using contradiction, upon trying some examples the statement we prove in our inductive steps becomes clear, at least intuitively, and so we need only ﬁnd a way to prove it rigorously. I ﬁnd that intuitively “obvious” statements are usually most easily proven by some ﬂavor of induction (normal, strong, recursive, or more rarely, prime), by parity, or by contradiction. In this case the result followed by strong induction. 4. (MOP 2006) Given positive integers d and n with d being a divisor of n. Set S contains all n-tuples (x1, x2, . . . , xn) of integers such that 0 ≤ x1 ≤ . . . ≤ xn ≤ n and d|x1 + . . . + xn. Prove that exactly half of the elements in S satisfy the property xn = n. Method One: We use two bijections: one from elements starting with zero and not ending with n to elements not starting with zero and ending with n, and the other from elements not starting with zero and not ending with n to elements starting with zero and ending with n. For the ﬁrst bijection, simply remove all zeroes at the beginning and add the same number of n’s at the end, and for the inverse mapping remove all n’s at the end and add the same num- ber of zeroes at the beginning. For the second bijection, represent the n-tuple (x1, . . . , xn) by an nxn grid in which the ﬁrst xi elements are colored black in row i, and the rest are colored white. Both the mapping and inverse mapping will be to reﬂect this grid across its main diagonal (i.e. rows become columns and columns become rows). There will be zeroes in the grid after applying this transformation iﬀ there were no n’s in the original grid, and likewise there will be n’s in the grid after applying the transformation iﬀ there were no zeroes in the original grid. Thus we have both bijections, and the desired result follows immediately. Comment: Looking for a bijection was very natural in this case because the problem asked us to prove that the number of elements in S with xn = n was equal to the number of elements with xn ̸= n. The ﬁrst bijection is fairly simple, but only works for some of the elements of S, so we need either to ﬁnd a bijection for the remaining elements or discard our original bi- jection altogether. The nxn grid used in the solution is a common and powerful visualization tool, and is often referred to as a “Young diagram.” Rotating the Young diagram is also a fairly common bijection to use. As it turns out, our original bijection was necessary because rotating the Young diagram doesn’t cover those cases. If one is already thinking along the lines of Young diagrams, it may be more natural to come up with the second bijection ﬁrst and then conjure the ﬁrst bijection to take care of the leftovers. Method Two (Anders Kaseorg): Consider the operation f : S → S deﬁned by (x1, . . . , xn−1, xn) 7→ (x1 + 1, . . . , xn−1 + 1, xn + 1) if xn ̸= n, and (x1, . . . , xn−1, n) 7→ (0, x1, . . . , xn−1) 15 f has a unique inverse, so f permutes S and f (S) = S, so the sum of all of the element of all of the n-tuples must be the same in S and f (S). Operations of the ﬁrst type increase the sum by n, and operations of the second type decrease the sum by n, so an equal number of each operation must occur. The desired result follows immediately. Comment: This solution is much more beautiful, and also easier to write up, but it is much harder to come up with. In fact, the proof itself does not use anything fancy, but it does exploit the often-overlooked fact that involutions (bijective functions mapping the domain onto itself) leave you again with the original set. This is an unorthodox use of a bijection, but it is good to keep in mind as it can lead to such beautiful solutions as this one. 5. (Topcoder) John is trapped inside a building, in which there are K main corridors and a central area connecting all of the corridors. Corridor i has a length li for 0 ≤ i < K. John starts at the end of Corridor 0, and, because of his desperation to escape, employs a very poor strategy. He runs to the center of the building and then randomly picks a corridor other than the one he just came from, then runs down that one (note that this means he may run down the same corridor multiple times). After having gone down every corridor at least once, John will realize that, in fact, none of the corridors have exits from the building, and he will stop running. What is the expected distance that he will run, in terms of l0, . . . , lK−1? Let l0 = N and l1+...+lK−1 K−1 = M . Then the expected distance is M + N + 2(K − 1)(M (K − 1) + N ) K K−2∑ i=1 1 i To prove this, we ﬁrst prove that the answer depends only on N and M (and K), as deﬁned above. This is because permuting the order of the last K − 1 corridors would not change the result, so if we were to make a tree based on his possible decisions, by symmetry it would have to involve him going down each of the last K − 1 corridors an equal number of times at each level, thereby proving that the expected distance would be the same for a ﬁxed sum of the last K − 1 distances, and by extension for their average value. Given this fact, we can therefore replace each of the last K − 1 distances with M without changing the answer. Then we arrive at the following recursion: g(n) = N + M + n K − 1 f (n) + K − 1 − n K − 1 f (n + 1) f (n) = M + K − 2 K − 1 M + 1 K − 1 N + n − 1 K − 1 f (n) + K − 1 − n K − 1 f (n + 1) + 1 K − 1 g(n) Where g(n) is the expected remaining distance starting at the end of the ﬁrst corridor and f (n) is the expected remaining distance starting at the end of one of the other corridors. In both cases n represents the number of visited corridors among the last K − 1. The ﬁrst recursion follows because John must go down the ﬁrst corridor, and then up one of the other corridors. Then he has an n K−1 chance of visiting a corridor he has already visited, and a K−1−n K−1 chance of visiting a new corridor. The second recursion follows because John must go 16 down one of the last K − 1 corridors, and then he has a K−2 K−1 chance of going up one of the last K − 1 corridors and a 1 K−1 chance of going down the ﬁrst corridor. Then he has a n−1 K−1 chance of going down an already visited corridor among the last K − 1, a K−1−n K−1 chance of going down a new corridor, and a 1 K−1 chance of going down the ﬁrst corridor. Substituting the formula for g into the formula for f , and performing some algebraic manipulation (bringing all of the terms involving f (n) over to the left-hand side, then dividing by their coeﬃcient), we arrive at the following equivalent formulation of the recursion: f (n) = 2(K − 1)(M (K − 1) + N ) K(K − 1 − n) + f (n + 1) Then let x = 2(K−1)(M (K−1)+N ) K . We wish to ﬁnd g(0). We have: f (K − 1) = 0 f (K − 2) = ( 1 1 )x + f (K − 1) = ( 1 1 )x f (K − 3) = ( 1 2 )x + f (K − 2) = ( 1 2 + 1 1 )x and so on, until we arrive at: f (1) = 1 K − 2 x + f (2) = x K−2∑ i=1 1 i g(0) = N + M + f (1) = N + M + 2(K − 1)(M (K − 1) + N ) K K−2∑ i=1 1 i This is identically the desired result, so we are done. Comment: This is an example of where using average value comes into play. Intuitively we might have suspected that, as we are looking for expected distance, only the average value of the last K − 1 matters. The argument for proving this is a bit sophisticated, but is good to become familiar with, as it recurs throughout multiple areas of mathematics. We might think to use this argument in an attempt to make recursion feasible, which should be one of the primary things to try when solving this problem, as it involves counting, and standard counting clearly fails, leaving recursion, bijections, and generating functions. (To me person- ally recursion is the easiest of these three, so I usually try it ﬁrst, but it probably diﬀers some from person to person.) This also serves as an example of how to write up a recursion, or a counting problem in general. It is important to justify how you arrive at each of your values or recurrence relations, even if it may seem “obvious” to you. 6. (MOP 2006) For i = 1, 2, . . . , 7, ai and bi are nonnegative numbers such that ai + bi ≤ 2. Prove that there exist distinct indices i, j such that |ai − aj| + |bi − bj| ≤ 1. We re-interpret the problem geometrically, considering the ordered pairs of the form (ai, bi). All points must lie in the triangle with vertices at (0, 2), (0, 0), and (2, 0). We label the fol- lowing points: A(0, 2),B(0, 1),C(0, 0),D( 1 2 , 3 2 ),E( 1 2 , 1 2 ),F (1, 1),G(1, 0), H( 3 2 , 1 2 ),I(2, 0). Then consider the following six regions: 17 (a) The triangle ADB. (b) The square BDF E. (c) The triangle BEC. (d) The triangle CEG. (e) The square EF HG. (f) The triangle GHI. By the Pigeonhole Principle, there must be at least two ordered pairs (ai, bi) and (aj, bj) in one of the regions. But it can be easily veriﬁed that if two ordered pairs are in the same re- gion, then |ai −aj|+|bi −bj| ≤ 1 for those two ordered pairs, the desired result, so we are done. Comment: It is a common and very useful strategy to take the geometric interpretation of a problem, as we did here. In essence, what we just did was to improve upon Continuous Pigeonhole in a speciﬁc case by dividing the triangle into six regions. The motivation for the solution is that it is much easier to think about distances in a plane than about the sums of the absolute values of the corresponding elements of two sets with a strange condition. Any simpliﬁcation or intuitive restatement of the problem cannot possibly be a bad thing. 7. (MOP 2006) A subset of positive integers is called a 2-dimensional base of positive integers if every positive integer n can be written as a sum of two (not necessarily distinct) numbers in A. Prove that there is a 2-dimensional base A and a constant C such that for every positive integer n, the set A ∩ {1, 2, . . . , n} has at most C√n elements. We will work in base 4. Consider ﬁrst the set of all integers whose digits in base 4 are only 0 or 1, and call this set X. Deﬁne Y similarly for 0 and 2. Let A be the union of X and Y . Then consider each digit separately. We can get 0 from 0 and 0, 1 from 1 and 0, 2 from 2 and 0, and 3 from 2 and 1. In all of these cases there are no carries. To prove that the desired constant C exists, consider that there are only 2k+1 − 1 = 2√4k − 1 numbers less than 4k that are in A. Thus, we have our desired bound and are done. Comment: At ﬁrst sight this solution looks like it was pulled out of nowhere. However, there is a lot of motivation behind it. First, when adding numbers together it is much easier, if possible, to just consider each digit separately (even better if you can avoid carries, as we did here). Once we are working with digits, it seems natural to try to limit the number of digits we care about, so we switch to base 2. But in base 2, we have to deal with several nasty cases in which the numbers carry over. To avoid this, we move to base 4, after which all of our case analysis becomes much nicer It is even possible to skip the case analysis and claim that powers of 2 up to 2n combined with 0 can get any number between 0 and 2n+1 − 1, a very well-known result provable by strong induction. In fact, this claim allows one to generalize the problem to n-dimensional bases, which may be worth mentioning in a write-up. 10 Problems Problems are given in rough order of diﬃculty, with estimated diﬃculty next to each problem, on a scale of 1-5. Diﬃculties of 1-2 correspond roughly to AIME 1-9, 2-3 to AIME 10-15, 3-4 to USAMO 1,2,4,5, and 4-5 to USAMO 5,6 and harder. 18 1. 1.2 (AIME) Given the set S of the ﬁrst 10 positive integers, how many unordered pairs exist such that each of the elements in the pair are non-empty subsets of S with no overlap? 2. 1.4 (AIME 1988/15) A secretary has 9 letters to type, which are delivered to her inbox throughout the day. When she has time she takes the letter on top and types it. At noon, letter 8 has already been typed (so letters 1-7 have already been delivered, and letter 9 may or may not have been delivered). How many typing orders are possible for the afternoon? 3. 1.4 (Gary Sivek 2006) S1 ⊆ S2 ⊆ . . . ⊆ Sk ⊆ {1, 2, . . . , n}. How many ordered k-tuples of integer sets exist that satisfy this condition? 4. 1.5 (HMMT Guts) Consider the set S of the ﬁrst 8 positive integers. How many sets can be formed such that each element of the set is a 2-element subset of S and no two sets overlap by more than 1 element? 5. 1.7 (Unknown) Consider some (not necessarily connected) set of points in the plane, with total area less than 1. Prove that one can move the set (through translations and rotations) so that it is not touching any lattice points. 6. 2.1 (Traditional) Prove that an n-element set must have some subset whose sum is divisible by n. 7. 2.3 (MCrawford) Suppose a baseball player has a probability p of hitting any given pitch. What is the probability that his batting average will ever be 0.5? 8. 2.6 (JSteinhardt) Take the ﬁrst kn positive integers, and partition them into sets S1 through Sk according to their congruencies modulo k. Arrange Si in increasing order if i is odd, and in decreasing order otherwise. Then create a sequence A consisting of the elements of S1 followed by the elements of S2, etc. (i) Determine, with proof, the length of the longest decreasing subsequence of A. (ii) Determine, with proof, the number of such subsequences. 9. 2.7 (MOP 2006) Let A = {a1, a2, . . . , ak}, and let B = {b1, b2, . . . , bk}, such that the elements of A and B are real numbers, 0 ≤ ai, bi ≤ n. Determine, with proof, the maximum value of (i) k−1∑ i=1 aibi+1 − ai+1bi, and (ii) ∑ i<j aibj − ajbi. 10. 3.2 (MOP 2006) Let n be a given integer greater than one. There are n bags of balls. The weight of each ball is a perfect power of two. (A bag can have balls of the same weight.) If the total weight of the balls in each bag is the same, then there necessarily exist at least kn total balls of the same weight. Determine the maximum value of kn. 11. 3.8 (USAMO 2002, 6) I take an N xN grid and cover 1x3 (either vertical or horizontal) regions on the grid until it is impossible to cover any more (the boundary of each region must coincide with the grid lines). If b(N ) is the least number of 1x3 regions needed to make it impossible to cover any more, prove that there exist constant C and D such that N 2 7 − CN ≤ b(N ) ≤ N 2 5 + DN . 12. 4.7 (JSteinhardt3) A path, which starts at (0, 0) and then goes from (x, y) to either (x+1, y−1) or (x + 1, y + 1) is considered good if it never goes below the line y = 0. Prove that there are(2n n ) good paths with ﬁnal x-coordinate 2n using a bijection. 3Thanks to Richard McCutchen for pointing out the bijection. 19 13. 4.9 (IMO Shortlist 2004, C84) For G a ﬁnite graph, let f (G) be the number of triangles and g(G) the number of tetrahedra formed by the edges of G. Find the least constant c such that g(G)3 ≤ cf (G)4 for all ﬁnite graphs G. 4Thanks to Thomas Mildorf for showing me this problem. 20","libVersion":"0.3.1","langs":""}