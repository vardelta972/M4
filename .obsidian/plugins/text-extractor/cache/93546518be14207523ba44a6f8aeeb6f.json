{"path":"iCloudDrive/bks/Combinatorics/Combinatorics/Probabilistic Method - David Arthur - Canada 2009.pdf","text":"Summer Camp 2009 The Probabilistic Method David Arthur The Probabilistic Method David Arthur ∗ darthur@gmail.com Sometimes you will run across Olympiad problems where the main challenge is to show that there exists an object with some speciﬁc property. If you’re lucky, you may just be able to write down what the object should be, and then observe it has the desired property. Often though, that is out of the question. There might be too many cases to consider, or the object you are looking for might be too complicated. So what do you do when that happens? In this talk, I am going to focus on one particular option: The Probabilistic Method: 1. Choose an object at random. The basic method: Choose an object uniformly at random. This means that each object is equally likely to be picked.1 Variations: You do not have to choose an object uniformly at random. You just need to describe a way of picking an object that has some randomness involved. As you will see, there are sometimes other eﬀective ways of doing this. 2. Prove that you will choose an object with the desired property with probability p > 0. Method #1: Often you will be looking for an object where some nu- meric quantity X has value at least y (or value at most y). If you can show that, on average, your random object will have value X = y, it follows immediately that in some case X ≥ y, and in some case X ≤ y. Method #2: You can also try to calculate the probability that your random object will not have the desired property. If you can prove this probability is less than 1 with inequality techniques, you are done. ∗Based partially on notes by Po-Shen Loh. 1Usually there are only ﬁnitely many objects to choose from, in which case this makes perfect sense. If there are an inﬁnite number of objects, things become more complicated. In particular, there is no such thing as choosing something uniformly at random from the set of all real numbers or from the set of all integers. You can choose a real number uniformly at random from a ﬁnite interval, or a point uniformly at random from a ﬁgure with ﬁnite area. The probability that a point lies in some region is then proportional to the length (or area) of that region. 1 of 7 Summer Camp 2009 The Probabilistic Method David Arthur Of course, anything that can be done with the probabilistic method can also be done with basic combinatorics. Method #1 combines counting with the Pigeonhole Principle, and method #2 combines counting with inequalities. Working in terms of probabilities often makes things simpler though, and it deﬁnitely helps guide your thinking. The techniques here are widely used in research mathematics and computer science, which should give you some indication that they are an eﬀective and elegant way of looking at the world! Anyway, let’s start with a basic example. Example 1. At the IMO, there are n students, and m pairs of these students are enemies. Prove that it is possible to divide the students into k rooms so that there are at most m k pairs of enemies that are placed in the same room as each other. Solution. Independently place each student in a random room. Now consider a ﬁxed pair of enemies. The probability that they will be placed in the same room is exactly 1 k . Therefore, on average, the number of pairs of enemies placed in the same room is exactly m k . (Do you see why?) In particular, there exists some conﬁguration where at most m k enemies are placed in the same room. This is a pretty easy problem, so you could also solve it by the extremal principle or by a greedy assignment. If you tried to directly translate the probabilistic argument into a counting argument though, things would get messy. 1 Calculating probabilities When applying the probabilistic method, it is very important to be comfortable with calculating probabilities! Here are a few facts that are particularly helpful. The ﬁrst two facts you are probably already familiar with, but the third may be new: • Let A and B be two random events. Then, Prob[A or B] = Prob[A] + Prob[B] − Prob[A and B]. In particular, Prob[A or B] ≤ Prob[A]+Prob[B]. This is called the union bound, and equality holds if and only if A and B are mutually exclusive. • If A and B are two random variables, we say A and B are independent if knowing A gives no information about B. For example, if I roll two dice, the rolls are independent from each other, but neither roll is independent from the sum. Then, A and B being independent is equivalent to the following: Prob[A = a and B = b] = Prob[A = a] · Prob[B = b] for all a, b. • For any probability p ∈ [0, 1] and any positive integer n, we have (1 − p)n ≤ e−np. This means that if A1, A2, . . . , An are random events that each happen independently with probability p, then at least one will happen with probability at least 1 − e−np. 2 of 7 Summer Camp 2009 The Probabilistic Method David Arthur Example 2. At the IMO, there are n people, some of whom are students and some of whom are guides. Each person brought k > log2 n diﬀerent colored shirts. To avoid confusion, the IMO wants to ensure that no guide is wearing the same colored shirt as a student. Prove that there is a choice of shirts which ensures this. Solution. For each shirt color, we choose randomly and independently whether it will be allowed for students or allowed for guides. We then need to show that with positive probability, every person has at least one shirt they can wear. Towards that end, consider a single person. The person owns k shirt colors, and the probability that all of them are assigned to the other side is exactly ( 1 2 )k. By the union bound, it follows that the probability of somebody having no valid shirts is at most n · ( 1 2 )k < n · ( 1 2 )log2 n = 1. Therefore, the probability of everybody having at least one valid shirt is greater than 0, and we’re done. 2 Expected value The example from the previous section used Method #2, but Method #1 comes up more often. The key to this is the idea of an expected value, which formalizes the “average” of some random variable. Deﬁnition 1. Let X be a random variable that takes values in some set S. Then, the expected value of S, denoted E[X], is E[X] = ∑ x∈S x · Prob[X = x]. The following facts are useful: • Let X be a random variable. Then, there is at least one case where X ≥ E[X], and there is at least one case where X ≤ E[X]. • If X and Y are random variables, then E[X + Y ] = E[X] + E[Y ], even if X and Y are not independent. This is called linearity of expectation and it is a lot more helpful than you might think at ﬁrst glance! • If X and Y are independent random variables, then E[X · Y ] = E[X] · E[Y ]. Exercise 1. If a fair coin is ﬂipped 100 times, what is the expected number of heads? Solution. Let X denote the total number of heads, and let Xi denote the number of heads on the ith coin toss. Then, X = ∑100 i=1 Xi and E[Xi] = 1 2 for all i, so linearity of expectation implies that E[X] = ∑100 i=1 E[Xi] = 50. Exercise 2. A fair coin is ﬂipped repeatedly until it turns up tails ﬁve times. What is the expected number of heads before that happens? Exercise 3. At the Pseudo-IMO, there are n students other than you, each from a diﬀerent country. Every day, you eat lunch with a random student, and they give you a miniature ﬂag from their country. Let X denote the number of days before you have at least one ﬂag from every country. What is E[X]? 3 of 7 Summer Camp 2009 The Probabilistic Method David Arthur With the background out of the way, let’s try using these ideas to solve an Olympiad problem. Example 3. (Russia 1996, #4) In the Duma, there are 1600 delegates who have formed 16000 committees of 80 persons each. Prove that one can ﬁnd two committees having at least four common members. Solution. Pick two committees independently and uniformly at random. Let X be the number of people in both committees, and let Xi be the {0,1}-random variable indicating whether the ith person is in both chosen committees. By linearity of expectation, E[X] = E[X1] + E[X2] + . . . + E[X1600]. The magic is that each E[Xi] is easy to calculate! Let ni be the number of committees that the ith person belongs to. Then, E[Xi] = Prob[ith person belongs to both committees] = (ni 2 )/(16000 2 ). Note that ∑1600 i=1 ni is just the total size of all committees, which is 16000 · 80, so the average value of {ni} is precisely n = 800. Since (x 2) is convex, we can now apply Jensen’s inequality: E[X] = 1600∑ i=1 (ni 2 ) /( 16000 2 ) ≥ 1600 · (n 2 ) /( 16000 2 ) = 1600 · 800 · 799 16000 · 15999 > 3.995. In particular, there exists some choice for which X is at least 3.995. Since X is an integer, it follows that X ≥ 4 in this case, and we’re done. Example 4. (Erd˝os, 1965) A set S is called sum-free if there is no triple of (not necessarily distinct) elements x, y, z ∈ S satisfying x + y = z. Prove that every set A of non-zero integers contains a subset S ⊆ A of size |S| > |A|/3, which is sum-free. Solution. Let p be a prime number of the form 3k + 2 such that p is greater than the maximum absolute value of any element in A.2 Also let C = {k + 1, k + 2, . . . , 2k + 1}, and note that this set is sum-free modulo p. Pick r uniformly at random from {1, 2, . . . , p − 1}, and consider multiplying each element of A by r, modulo p. Since p is large, every element in A is non-zero modulo p. Therefore, each element in A has probability exactly |C| p−1 > 1 3 of mapping into C when multiplied by r. Linearity of expectation then implies that the expected number of elements mapping into C is > |A| 3 . Let S be the set of these elements. We know there exists some choice of r for which |S| ≥ E[|S|] > |A| 3 . It remains only to show that S is sum-free. Indeed, if x, y, z ∈ S, then xr + yr ̸≡ zr(mod p) since xr, yr, zr ∈ C, and hence, x + y ̸= z. 2The existence of such a prime number p is implied by Dirichlet’s prime number theorem, which states that for any relatively prime positive integers a and d, the arithmetic sequence a, a + d, a + 2d, . . . contains inﬁnitely many primes. This theorem is diﬃcult to prove in general but there is an elementary proof for a = 2, d = 3. Can you ﬁnd it? 4 of 7 Summer Camp 2009 The Probabilistic Method David Arthur 3 Problems The following problems can all be solved with the probabilistic method. In many cases, it simpli- ﬁes and motivates things very nicely – in other cases, you may feel more comfortable with pure combinatorial thinking. Use whatever you are comfortable with! The last few problems are very diﬃcult, and actually come from research mathematics, so beware! 1. (Canadian MO 2009, #2) Two circles of diﬀerent radii are cut out of cardboard. Each circle is subdivided into 200 equal sectors. On each circle 100 sectors are painted white and the other sectors are painted black. The smaller circle is then placed on top of the larger circle, so that their centers coincide. Show that one can rotate the small circle so that the sectors on the two circles line up and at least 100 sectors on the small circle lie over sectors of the same color on the big circle. 2. (MOP 2007) In an n × n array, each of the numbers 1, 2, . . . , n appears exactly n times. Show that there is a row or a column in the array with at least √n distinct numbers. 3. (Korean MO 2008, #6) There is an n × n grid on a computer. Each of its n2 squares displays an integer from 0 to k. For each of the n rows and each of the n columns, there is also a button that, if pressed, will increase every number in that row or column by 1. If a number ever reaches k, it immediately changes to 0. Initially, every square displayed 0, but then a number of buttons were pressed. Show that after at most kn more button presses, it is possible to change every number back to 0 again. 4. Let v1, v2, . . . , vn be unit vectors in Rd. Prove that it is possible to assign weights ϵi ∈ {±1} such that the vector ∑ ϵivi has Euclidean norm3 less than or equal to √n. 5. (IMO 1987, #3) Let x1, x2, . . . , xn be real numbers satisfying x2 1 + x2 2 + . . . + x2 n = 1. Prove that for every integer k ≥ 2, there are integers a1, a2, . . . , an, not all zero, such that |ai| ≤ k−1 for all i, and |a1x1 + a2x2 + . . . + anxn| ≤ (k − 1) √n kn − 1 . 6. (IMO Shortlist 1999, C4) Let A be any set of n residues mod n2. Show that there is a set B of n residues mod n2 such that at least half of the residues mod n2 can be written as a + b with a ∈ A and b ∈ B. 7. (Iran TST 2008, #6) Suppose 799 teams participate in a tournament in which every pair of teams plays against each other exactly once. Prove that there two disjoint groups A and B of 7 teams each such that every team from A defeated every team from B. 8. (Austrian-Polish math competition 1997, #8) Let n be a natural number and M a set with n elements. Find the largest integer k such that there exist k 3-element subsets of M , no two of which are disjoint. 3The Euclidean norm of a vector v = (x1, x2, . . . , xd) is deﬁned to be √ x 2 1 + x 2 2 + . . . + x 2 d, and a unit vector is a vector with Euclidean norm equal to 1. 5 of 7 Summer Camp 2009 The Probabilistic Method David Arthur 9. (USAMO 1995, #5) Suppose that in a certain society, each pair of persons can be classiﬁed as either amicable or hostile. We shall say that each member of an amicable pair is a friend of the other, and each member of a hostile pair is a foe of the other. Suppose that the society has n persons and q amicable pairs, and that for every set of three persons, at least one pair is hostile. Prove that there is at least one member of the society whose foes include q(1 − 4q/n2) or fewer amicable pairs. 10. (Taiwan 1997, #9) For n ≥ k ≥ 3, let X = {1, 2, . . . , n}, and let Fk be a family of k-element subsets of X such that any two subsets in Fk have at most k − 2 common elements. Show that there exists a subset Mk of X with ⌊log2 n⌋ + 1 elements containing no subset in Fk. 11. (Canadian Winter camp 2009) We are given a collection T of circles of radius 1, which together cover an area S in the plane. Show that it is possible to choose a collection of non-overlapping circles from T which together cover an area that is greater than or equal to π 8 √3 · S. 12. (Romanian master in mathematics competition 2008, #4) Prove that from among any (n+1)2 points inside a square of side length positive integer n, one can pick three that form a triangle with area at most 1 2 . 13. (Erd˝os-Ko-Rado theorem) Let n, k be positive integers satisfying n ≥ 2k, and let C be a collection of pairwise-intersecting k-element subsets of {1, 2, . . . , n}. Prove that |C| ≤ (n−1 k−1). 14. (Sperner’s other lemma) Let C be a collection of subsets of {1, 2, . . . , n} such that no two distinct subsets A, B ∈ C satisfy A ⊆ B. Prove that |C| ≤ ( n ⌊n/2⌋ ). 15. (Bollob´as 1965, and Summer camp 2008) Let X be a ﬁnite set, and suppose A1, A2, . . . , Am, and B1, B2, . . . , Bm are subsets of X with |Ai| = r and |Bi| = s for all i. If Ai ∩ Bi = ∅ for all i and Ai ∩ Bj ̸= ∅ for all i ̸= j, prove that m ≤ (r+s r ). 16. (Crossing lemma) A graph with V vertices and E edges is drawn in the plane. Show that, as long as E ≥ 4V , there will be at least E3 64V 2 pairs of edges that cross. 17. (Karger 1993) In a connected, undirected graph, a collection of edges is called a cut if removing those edges will disconnect the graph. A cut is called a min-cut if there is no cut with fewer edges. Prove that the maximum number of min-cuts on a graph with n vertices is exactly (n 2). 6 of 7 Summer Camp 2009 The Probabilistic Method David Arthur 4 Selected hints 11. Tile the plane with circles and then add randomness. By the way, this result is quite tight. π 8 √3 ≈ 0.227, and it is pretty easy to show that the best possible bound is at most 0.25. 12. Suppose the convex hull of the points has k points on the boundary, perimeter P , and area A. Prove that some triangle has area at most min ( P 2 2k2 , A 2(n+1)2−k−2 ). 13. Fix a permutation σ of {1, 2, . . . , n}, and consider the sets Xi = {σ(i), σ(i+1), . . . , σ(i+k−1)} (taking all indices mod k). 14. Fix a permutation σ of {1, 2, . . . , n}, and consider the sets Xi = {σ(1), σ(2), . . . , σ(i)}. Cal- culate the expected number of sets Xi in C. 15. Pick a random labeling {1, 2, . . . , n} of X. Consider the event Ei where every element in Ai has label less than every element in Bi. Use the fact that 1 ≥ Prob[At least one event Ei happens]. 16. First show the number of crossing edges is at least E − 3V (using the fact that a planar graph has V − E + F = 1 =⇒ E < 3V ). Now sample vertices independently with some probability p and apply this inequality. 17. Consider the following algorithm for ﬁnding a cut. Choose a random edge. Merge the two endpoints, deleting all edges between those endpoints but keeping all other edges. Note that it may be possible to now have multiple edges between the same two vertices – that’s ok. Repeat this contraction process until only two vertices remain. The remaining edges form a cut of the original graph (why?). Given a ﬁxed min-cut, what is the probability that this algorithm will ﬁnd it at the end? 7 of 7","libVersion":"0.3.1","langs":""}