{"path":"iCloudDrive/bks/Algebra/Algebra/Polynomials/Polynomials I - Holden Lee - OMC.pdf","text":"Lecture 8 — Polynomials, Part 1 Holden Lee 1/29/2011 1 What is a polynomial? In this section, we will formally deﬁne polynomials. (As this is somewhat abstract, feel free to skip on ﬁrst reading.) In general we will use R to denote a ring and K to denote a ﬁeld; in later sections the reader may substitute K with either the rationals Q, reals R, or complex numbers C without too much loss in generality. Before we can deﬁne a polynomial, we have to decide what coeﬃcients we allow. Often we will just work with real numbers, but it is helpful to have the freedom to choose between C, R, Q, Z, Z/pZ (integers modulo p), and so forth. The set of coeﬃcients should form a ring, where addition and multiplication satisfy all the properties we expect them to. We need this before we can think of deﬁning addition and multiplication for polynomials. Deﬁnition 1.1: A ring is a set R with the operations of addition (+) and multiplication (×) satisfying: 1. R is an abelian group under addition. That is, the following hold: (a) (Associativity) (a + b) + c = a + (b + c). (b) (Commutativity) a + b = b + a. (c) (Additive identity) There exists an (unique) element 0 such that a+0 = 0+a = a for any a. (d) (Additive inverse) For every a there exists an (unique) element −a such that a + (−a) = (−a) + a = 0. 2. Multiplication satisﬁes similar properties, except the last: (a) (Associativity) (ab)c = a(bc). (b) (Commutativity) ab = ba. (c) (Multiplicative identity) There exists an (unique) element 1 such that 1a = a1 = a. 3. Multiplication distributes over addition; that is, a(b + c) = ab + ac and (a + b)c = ac + bc. A ﬁeld is a ring such that every nonzero element has a multiplicative inverse: if a ̸= 0 then there exists an (unique) element a−1 such that aa−1 = a−1a = 1. OMC 2011 Polynomials Lecture 8 Examples of ﬁelds are C, R, Q, and Z/pZ. In later sections, unless otherwise speciﬁed, we will only consider polynomials over a ﬁeld. Now we can go ahead to deﬁne polynomials. Deﬁnition 1.2: The polynomial ring R[x] is the set of expressions of the form ∑∞ n=0 anxn where an ∈ R and only a ﬁnite number of an are nonzero. Addition is deﬁned by adding corresponding terms and multiplication is deﬁned using the distributive law (i.e. multi- plying every term in the ﬁrst polynomial by every term in the second, and adding up all the terms). It is simple to verify that R[x] is a ring (just check all the properties... the only one of much substance is associativity). By repeating this process we can get polynomials in multiple variables (R[x, y] = R[x][y], etc.). Often we think of polynomials as functions, that is we can evaluate the polynomial at any x ∈ R. Proposition 1.3: (Substitution) Given any t ∈ R, there is a function R[x] → R that sends a polynomial P (x) = ∑∞ n=0 anxn to its value at t, ∑∞ n=0 ant n. We call this value P (t). This extends in a straightforward manner to polynomials in more variables. A word of caution: two polynomials may give the same function, but are still diﬀerent when considered as polynomials—because two polynomials are equal iﬀ all their coeﬃcients are equal. For example, we know from Fermat’s Little Theorem that xp − x = 0 for all x ∈ Z/pZ. Hence as functions, xp − x and 0 are indistinguishable. However they are not the same polynomial. In abstract algebra, we often formulate Proposition 1.3 in the following way: Proposition 1.4 (Universal Mapping Property): R[x1, . . . , xn] is the unique ring, up to isomorphism, with the following property: Given t1, . . . , tn ∈ R, there is a unique ring homomorphism from R[x1, . . . , xn] to R sending xi to ti. (A ring homomorphism ϕ is a function which preserves addition, multiplication and 1, i.e. ϕ(a + b) = ϕ(a) + ϕ(b), ϕ(ab) = ϕ(a)ϕ(b), ϕ(1) = 1. An isomorphism is a homomorphism with an inverse.) Here’s some basic deﬁnitions (that you probably already know): Deﬁnition 1.5: A zero (or root) of P (x) is a value t such that P (t) = 0. The degree of a polynomial P (x) = ∑ n≥0 anxn is the largest n such that an ̸= 0. (The degree of 0 is said to be −∞.) A polynomial is monic if its leading coeﬃcient is 1. Now that we have the theory of polynomials on a solid footing, we can move on to more concrete concepts! 2 Values and Zeros Proposition 2.1: Let K be a ﬁeld (such as R, C, Z/pZ, . . .). If p ∈ K[x] and p(x0) = 0, then p(x) = (x − x0)q(x) for some polynomial q. Proof. By division with remainder, we can write p(x) = (x − x0)q(x) + r(x) 2 OMC 2011 Polynomials Lecture 8 where the remainder term r(x) has strictly smaller degree than x − x0. Hence r(x) is a constant. Substitute x = x0 to get 0 = r(x0). Therefore, r(x) = 0. Note that the same idea also proves the Remainder Theorem (how?). Now if we know that r1, . . . , rn are roots of p(x), then we can factor p(x) = (x − r1) . . . (x − rn)q(x). In particular, if p(x) has degree at most n, then p(x) = c(x − r1) . . . (x − rn) for some constant c. This gives the following fundamental facts. Theorem 2.2: 1. Over a ﬁeld, a polynomial of degree at most n that is zero for n + 1 values of x is identically 0. In other words, a polynomial of degree n > 0 can have at most n zeros. 2. Two polynomials of degree at most n that are equal for n + 1 values of x are identically equal. 3. A polynomial which is zero for inﬁnitely many values is identically 0. Proof. 1. If the zeros are r1, . . . , rn+1 then as above we factor p(x) = (x − r1) · · · (x − rn+1)q(x). Since p(x) has degree at most n, we must have q(x) = 0. 2. If p(x) = q(x) for n + 1 values of x, then applying part 1 to p(x) − q(x) shows that p(x) − q(x) = 0. 3. Immediate since every nonzero polynomial has ﬁnite degree. Now comes our ﬁrst strategy for tackling polynomial problems. Get something in the form Q(x) = 0 and factor based on roots. Plug in a value to get the leading coeﬃcient. Alternatively “guess” a polynomial satisfying the equations, and use Theorem 2.2 to show it is correct. Example 2.3: A polynomial P of degree n satisﬁes P (x) = x x+1 for x = 0, 1, . . . , n. Find P (n + 1). Solution. Rearrange to get (x + 1)P (x) − x = 0 for x = 0, 1, . . . , n. Since this equation has roots x = 0, 1, . . . , n, and the left-hand side has degree n + 1, (x + 1)P (x) − x = kx(x − 1) · · · (x − n) for some integer k. Then P (x) = kx(x − 1) · · · (x − n) + x x + 1 . The numerator must be divisible by x + 1 so must have x = −1 as a zero. Plugging in, we get (−1) n+1(n + 1)!k − 1 = 0, or k = (−1)n+1 (n+1)! . Plugging in x = n + 1 gives P (n + 1) = { 1, n odd n n+2, n even. 3 OMC 2011 Polynomials Lecture 8 □ Alternatively, we can ﬁnd an explicit, although somewhat messy, formula for a poly- nomial given its values. Theorem 2.4 (Lagrange Interpolation): Given n + 1 points (x0, y0), . . . , (xn, yn) with distinct x-coordinates, there exists exactly one polynomial f of degree at most n so that f (xi) = yi for i = 0, 1, . . . , n. This polynomial is given by the following: P (x) = n∑ i=0 [ yi ∏ j̸=i x − xj xi − xj ] . Proof. Note that the ith term in the sum (0 ≤ i ≤ n) is engineered so that it has a zero at xj for j ̸= i. Thus, only the ith term contributes to the sum evaluated at xi. We have P (xi) = yi ∏ j̸=i xi − xj xi − xj = yi. (The constant yi ∏ j̸=i 1 xi−xj just so this would happen.) Hence P satisﬁes the conditions of the problem. Uniqueness follows at once from Theorem 2.2(2). Here’s an example. Example 2.5: Let r ≥ 3. Prove that there does not exists a real polynomial of degree at most n so that |p(x) − rx| < 1 for x = 0, 1, . . . , n + 1. Proof. Suppose |p(x) − rx| < 1 for x = 0, 1, . . . , n. Let yi = p(i) for 0 ≤ i ≤ n. By the Lagrange Interpolation Formula, p(x) = n∑ i=0 [ yi ∏ j̸=i x − j i − j ] . When ri − 1 ≤ yi ≤ ri + 1, p(n + 1) is maximized when we take yi = ri − 1 when the product is negative (i.e. when n − i is odd) and yi when the product is positive (i.e. when n − i is even): p(n + 1) < n∑ i=0 (ri + (−1)n−i) ∏ j̸=i (n + 1) − j i − j = n∑ i=0 (ri + (−1)n−i)(−1) n−i (n + 1)! i!(n + 1 − i)! = n∑ i=0 [( n + 1 i ) ri(−1) n−i + ( n + 1 i )] = −((r − 1)n+1 − rn+1) + (2n+1 − 1) by the Binomial Theorem = rn+1 − 1 + 2n+1 − (r − 1) n+1 ≤ rn+1 − 1 Note an alternate solution is to use Lagrange Interpolation with n + 2 points and show that the coeﬃcient of xn+1 cannot be 0. 4 OMC 2011 Polynomials Lecture 8 Next we introduce the derivative. Although the motivation for the derivative comes from calculus, for polynomials it can be deﬁned purely in algebraic terms, and its proper- ties can be proved algebraically. Hence it is useful even for polynomials over rings where there is no clear notion of distance, such as Z/pZ. Deﬁnition 2.6: Let f (x) = ∑ n≥0 anxn be a polynomial. The derivative of f (x) is deﬁned as f ′(x) = ∑ n≥1 nanxn−1. The following can easily be veriﬁed by the reader. Proposition 2.7: Let f, g be two polynomials and c be a constant. Then 1. (Linearity) (cf + g) ′ = cf ′ + g′. 2. (Product rule) (f g) ′ = f ′g + f g′. 3. (Chain rule) (f ◦ g) ′ = (f ′ ◦ g)g′. Derivatives are useful in detecting repeated zeros. We assume the ﬁeld is R or C. Proposition 2.8: If (x−a)n is the highest power of x−a dividing f (we write (x−a) n||f ), then (x − a) n−1||f ′. Thus, a is a root of f of multiplicity n iﬀ f (a), f ′(a), . . . , f (n−1)(a) are all zero but f (n)(a) is not. Proof. Writing f = (x − a) ng where x − a ∤ g, we see by the product rule that f ′(x) = n(x − a)n−1g + (x − a)ng′, so the statement follows. The second part follows by repeatedly taking derivatives. 2.1 Problems 1. Let r ̸= 0 be a real number. A polynomial P of degree n satisﬁes P (x) = rx for x = 0, 1, . . . , n. Find P (n + 1). 2. n points Q1, . . . , Qn are equally spaced on a circle of radius 1 centered at O. Point P is on ray OQ1 so that OP = 2. Find the product n∏ k=1 P Qk in closed form, in terms of n. 3. (AwesomeMath Team Contest 2010) Let n ≥ 2. How many polynomials Q(x) of degree at most n − 1 are there such that x(x − 1) · · · (x − n)Q(x) + x2 + 1 is the square of a polynomial? 4. (APMO 2009/2) Let a1, a2, a3, a4, a5 be real numbers satisfying the following equa- tions: a1 k2 + 1 + a2 k2 + 2 + a3 k2 + 3 + a4 k2 + 4 + a5 k2 + 5 = 1 k2 for k = 1, 2, 3, 4, 5. Find the value of a1 37 + a2 38 + a3 39 + a4 40 + a5 41 . 5 OMC 2011 Polynomials Lecture 8 5. (UM 2002/3) Imagine ducks as points in a plane. Three ducks are said to be in a row if a straight line passes through all three ducks. Three ducks, Huey, Dewey, and Louie, each waddle along a diﬀerent straight line in the plane, each at his own constant speed. Although their paths may cross, the ducks never bump into each other. Prove that if at three separate times the ducks are in a row, then they are always in a row. 6. (IMC 2008/B4) Let f (x), g(x) be nonconstant polynomials with integer coeﬃcients such that g(x) divides f (x). Prove that if the polynomial f (x) = 2008 has at least 81 distinct integer roots, then the degree of g(x) is greater than 5. 7. (USAMO 2002/3) Prove that any monic polynomial of degree n with real coeﬃcients is the average of two monic polynomials of degree n with n real zeros. 8. (Putnam 1956) The nonconstant polynomials f (z) and g(z) with complex coef- ﬁcients have the same set of numbers for their zeros but possibly with diﬀerent multiplicities. The same is true of the polynomials f (z) + 1 and g(z) + 1. Prove that f (z) = g(z). (Hint: take derivatives) 3 Symmetric Polynomials and Vieta’s Formulas Often we want to evaluate symmetric functions of the roots without actually computing them. Vieta’s formula allows us to do this. First, a deﬁnition. Deﬁnition 3.1: A symmetric polynomial in n variables P (x1, . . . , xn) is such that, for any permutation xσ(1), . . . , xσ(n) of the variables x1, . . . , xn, we have P (x1, . . . , xn) = P (xσ(1), . . . , xσ(n)). An elementary symmetric polynomial (or function, or sum) is one in the form sj = ∑ 1≤i1<...<ij ≤n xi1 · · · xij for some 0 ≤ j ≤ n. (Note s0 = 1.) For example, x2 1x2 + x1x2 2 + x2 2x3 + x2x2 3 + x2 3x1 + x3x2 1 is a symmetric polynomial in 3 variables. Theorem 3.2 (Vieta’s Formula): Let r1, . . . , rn be the roots of P (x) = ∑n i=0 aixi, and let sj = ∑ 1≤i1<...<ij ≤n ri1 · · · rij . Then sj = (−1) j an−j an . Proof. We can factor the polynomial as P (x) = an(x − r1)(x − r2) · · · (x − rn). Dividing by an gives (xn + an−1 an xn−1 + · · · + a1 an x + a0 an ) = (x − r1)(x − r2) · · · (x − rn). 6 OMC 2011 Polynomials Lecture 8 In the expansion of the right-hand side, the terms containing xn−j are of the form (−ri1) · · · (−rij )xn−j—they contain a product of j roots. Summing them up, the co- eﬃcient of xn−j is (−1)jsj. Setting this equal to the coeﬃcient on the left-hand side, an−j an , gives the desired result. Example 3.3: Let r1, r2 be the roots of the quadratic ax2 + bx + c = 0. Find 1. r1 + r2 2. r2 1 + r2 2 3. r3 1 + r3 2 Solution. 1. From Vieta’s formula, r1 + r2 = − b a . 2. Also from Vieta’s formula, r1r2 = c a . We need to combine these two expressions in some way to form r2 1 + r2 2. The following identity does the trick. r2 1 + r2 2 = (r1 + r2) 2 − 2r1r2. Thus r2 1 + r2 2 = ( − b a )2 − 2 ( c a ) = b2−2ac a2 . 3. Noting the cube, we ﬁrst cube r1 + r2 to get r3 1 + 3r2 1r2 + 3r1r2 2 + r3 2. We need to get rid of 3r2 1r2 + 3r1r2 2. But we are in luck, since this equals 3r1r2(r1 + r2). Hence r3 1 + r3 2 = (r1 + r2) 3 − 3r1r2(r1 + r2). (Another way to see this is to use the factorization r3 1 +r3 2 = (r1+r2)(r2 1 −r1r2+r2 2) = (r1 + r2)((r1 + r2) 2 − 3r1r2).) We get r3 1 + r3 2 = ( − b a)3 − 3 ( c a ) ( − b a ) = −b3+3abc a3 . The examples above suggest that no matter what symmetric polynomial in the roots we are given, we can always write it in terms of the elementary symmetric functions, by simply matching the “highest degree term” at each step and then focusing on the remaining terms, of smaller degree. This is indeed true, and holds for arbitrarily many variables. Theorem 3.4 (Fundamental Theorem of Symmetric Polynomials): Let P ∈ R[x1, . . . , xn] be a symmetric polynomial in n variables. Then there exists a polynomial Q ∈ R[x1, . . . , xn] such that P (x1, . . . , xn) = Q(s1, . . . , sn), where si is the ith elementary symmetric polynomials. In other words, every symmetric polynomial can be written in terms of elementary symmetric polynomials. Note that Q has coeﬃcients in the same ring as P : for example, if P has integer coeﬃcients, then Q will have integer coeﬃcients as well. Proof. We induct on the degree and the number of variables. For deg P = 0 or n = 1 the assertion is obvious (in the latter case x1 is the sole elementary symmetric polynomial and P = Q). Now assume the assertion proved for polynomials of the same number of variables but with smaller degree than P , and proved for polynomials of fewer variables 7 OMC 2011 Polynomials Lecture 8 than P . Consider P (x1, . . . , xn−1, 0) as a polynomial in n − 1 variables. Since it is symmetric in x1, . . . , xn−1, by the induction hypothesis it can be written as P (x1, . . . , xn−1, 0) = R(s′ 1, . . . , s′ n−1) where s′ j = ∑ 1≤i1<...<ij ≤n−1 xi1 · · · xij . Then P (x1, . . . , xn) − R(s1, . . . , sn−1) is zero when xn = 0 (because then sj = s′ j), so P (x1, . . . , xn−1, xn) − R(s1, . . . , sn−1) = xnS(x1, . . . , xn). Since P and R are symmetric polynomials in the xi, so is xnS(x1, . . . , xn). Since xn divides xnS(x1, . . . , xn) and this polynomial is symmetric, so do xj for all 1 ≤ j ≤ n. Then xn = S(x1, . . . , xn) = x1 · · · xnT (x1, . . . , xn) for some symmetric T . Since T has smaller degree, it can be written in terms of symmetric polynomials by the induction hypothesis, say as U (s1, . . . , sn). Then P (x1, . . . , xn) = R(s1, . . . , sn−1) + snU (s1, . . . , sn) is the desired representation. Note the proof gives a constructive way to ﬁnd the representation. Finally, a particularly interesting case is when the symmetric polynomial is a sum of powers, xj 1 + · · · + xj n. In this case we can use the following formula to ﬁnd the representation in terms of elementary symmetric functions. Theorem 3.5 (Newton Sums): Let sj denote the jth elementary symmetric polynomial in x1, . . . , xn and pj denote the power sum xj 1 + · · · + xj n. (By deﬁnition, p0 = n and s0 = 1). Note that if j > n, then sj is deﬁned to be 0. Then for all m ≥ 1, m∑ k=0(−1) kskpm−k = s0pm − s1pm−1 + · · · + (−1) m−1sm−1p1 + (−1)msmp0 = 0. 3.1 Problems 1. (AIME1 2001/3) Find the sum of the roots of the equation x2001 + ( 1 2 − x)2001 = 0 (given that there are no multiple roots). 2. Find the sum of the squares of the reciprocals of the roots of x5 + 3x4 + 5x3 + 7x2 + 9x + 11 = 0. 3. Given that the zeros of x3 + ax2 + bx + c = 0 are r1, r2, r3, ﬁnd the monic cubic polynomials whose roots are... (a) 1 r1 , 1 r2 , 1 r3 (b) r1 + r2, r2 + r3, r3 + r1 (c) r2 1, r2 2, r2 3 4. (AIME2 2008/7) Let r, s, and t be the three roots of the equation 8x3 + 1001x + 2008 = 0. Find (r + s)3 + (s + t)3 + (t + r) 3. 8 OMC 2011 Polynomials Lecture 8 5. (AIME1 2005/8) The equation 2 333x−2 + 2111x+2 = 2 222x+1 + 1 has three real roots. Given that their sum is m n where m and n are relatively prime positive integers, ﬁnd m + n. 6. (AIME2 2003/9) Consider the polynomials P (x) = x6 − x5 − x3 − x2 − x and Q(x) = x4 − x3 − x2 − 1. Given that z1, z2, z3, and z4 are the roots of Q(x) = 0, ﬁnd P (z1) + P (z2) + P (z3) + P (z4). 7. (IMO 1988/4) Show that the solution set of the inequality 70∑ k=1 k x − k ≥ 5 4 is the union of disjoint half-open intervals with sum of lengths 1988. 4 The Fundamental Theorem of Algebra We give two standard proofs of the following. (Note we’ve used it implicitly in the last section, when we assumed a polynomial of degree n has n complex roots.) Theorem 4.1 (Fundamental Theorem of Algebra): Any nonconstant complex polyno- mial has a zero in C. Hence by induction every complex polynomial splits completely into linear factors P (x) = c(x − r1) . . . (x − rn). By scaling, it suﬃces to show this for P (x) = xn + an−1xn−1 + . . . + a0. The ﬁrst proof requires a theorem from analysis. Theorem 4.2: A continuous real-valued function on a compact set attains a maximum and minimum. In R or C, a compact set is a closed and bounded set. A subset S of R or C is said to be closed if whenever S has elements arbitrarily close to a certain number x, then it contains x. For example, [a, b] is closed in R, but (a, b] is not, because the latter contains points arbitrarily close to a but unequal to a. In fact 1 x−a is a function deﬁned on the latter interval that is not bounded. This theorem says that this would not happen on something like [a, b]. Proof. Main idea: If P does not have a zero, take x such that it |P (x)| attains minimum. We can move a small amount in one direction to make |P (x)| smaller, a contradiction. Step 1: |P | attains a minimum. Note that if x has absolute value at least S, then |P (x)| is at least Sn−|an−1|Sn−1−· · · . This approaches inﬁnity as S approaches inﬁnity. Hence the inﬁmum (greatest lower bound) of |P | is the same as if we restrict it to some suﬃciently large ball around 0, |x| ≤ S for some S. But this is a compact set, as it is closed and bounded, so |P | attains a minimum here, say at x0. Suppose that P (x0) ̸= 0. Step 2: Adjust x. 9 OMC 2011 Polynomials Lecture 8 For convenience, set Q(x) = P (x0+x) Q(x0) ; that is, Q is a shifted and scaled version of P so that Q(0) = 1 is the minimum of |Q|. Write Q(x) = 1 + bkxk + bk+1xk+1 + · · · where bk ̸= 0. Then 1 Q(reiθ) = 1 + bkrkeiθk + rk+1(bk+1e iθ(k+1) + · · · ) However, \f \f \f \frk+1(bk+1eiθ(k+1) + · · · ) bkrkeiθk \f \f \f \f → 0 as r → 0. We can choose the direction θ so that bkrke iθk is negative. By the triangle inequality |Q(reiθ)| < 1 − |bkrk| + |rk+1(bk+1e iθ(k+1) + · · · )|. However, we’ve shown that the last term is negligible compared to the second term as r → 0, so choosing r > 0 small enough we get |Q(reiθ)| < 1, contradiction. The second proof uses ideas from algebraic topology, as hinted by the ﬁrst lecture. Proof. Main idea: Let x range over the circles g(θ) = re2πiθ, θ ∈ [0, 1] for diﬀerent r. For r = 0, P (x) is just the constant path a0 and does not go around 0; for large r, the xn term dominates, and the path resembles g(θ) n which goes around 0 n times. Thus for some intermediate r, P (x) passes through 0. We need to make precise what it means for P (x) to “wind” n times around 0, and prove that it is invariant under “deforming” a path (without having it pass through 0). Suppose that P has no zero. Obviously, a0 ̸= 0 as else x = 0 is a zero. Let Pr(θ) = P (gr(θ)). We think of this as a family of functions (or paths) [0, 1] → C. For any r, we have that P0 ≡ a0 deforms continuously to Pr, (1) as Pr(θ) is continuous in r and θ. Now, xn winds n times around 0 as x goes around the circle gr(θ), and |xn| > |an−1xn−1 + . . . | for suﬃciently large r. Thus for such a r = R, PR(θ) sticks close to xn as x varies around the circle, following xn around 0 n times. Indeed, PR(θ) deforms continuously into rne 2πin. (2) To see this, deﬁne ft(θ) = (gR(θ)) n + t(an−1gR(θ) n−1 + . . .). Then ft(x) for 0 ≤ t ≤ 1 deforms from f0(θ) = rne 2πniθ to f1(θ) = PR(θ) in C − {0} (since |xn| > |an−1xn−1 + . . . |, none of the ft pass through 0). (In topology these “deformations” are called homotopies.) From (1) and (2), the point a0 deforms continuously into the function rne2πin, a circle going through the origin n times, without passing through 0. However this is a contradiction (although to show it rigorously requires some topology), unless n = 0, in which case P is a constant polynomial. Example 4.3: Let f (x) be a real polynomial such that f (x) ≥ 0 for all real x. Then there exist real polynomials g(x), h(x) such that f (x) = g(x)2 + h(x) 2. 1re iθ = cos θ + i sin θ 10 OMC 2011 Polynomials Lecture 8 Proof. By the Fundamental Theorem of Algebra, f (x) splits completely into linear factors x−ri. Since f (x) is real, all its zeros (counted with multiplicity) are either real or come in complex conjugate pairs. Since f (x) ≥ 0 for all i, all zeros must have even multiplicity— otherwise f (x) would change sign at that zero. Hence the real roots can be paired up (trivially) into complex conjugate pairs as well. Then we can write f (x) = c(x − r1)(x − r1) · · · (x − rn)(x − rn) where c ≥ 0. Let f1(x) = √ c(x − r1) · · · (x − rn) and f2(x) = √c(x − r1) · · · (x − rn). Then f1 and f2 are conjugate, so writing f1(x) = g(x) + ih(x) for real polynomials g and h, we see that f2(x) = g(x) − ih(x). Hence f (x) = f1(x)f2(x) = [g(x) + ih(x)][g(x) − ih(x)] = g(x)2 + h(x) 2, as desired. 4.1 Problem 1. How many ordered pairs of real polynomials (g(x), h(x)) are there so that g(x)2 + h(x) 2 = x20 − 1 x2 − 1 ? 11","libVersion":"0.3.1","langs":""}