{"path":"iCloudDrive/bks/Calculus/Handouts/Laplace Transforms Detailed (Very Advance).pdf","text":"The Laplace Transform 18.031, Haynes Miller and Jeremy Orloﬀ 1 Laplace transform basics: introduction An operator takes a function as input and outputs another function. A transform does the same thing with the added twist that the output function has a diﬀerent independent variable. The Laplace transform takes a function f (t) and produces a function F (s). We will allow the variable s to be complex. As with the transfer function you learned about earlier the s will be thought of as complex frequency You should think of f (t) and F (s) as two views of the same underlying object. If we have a signal, then f (t) is the familiar view of that signal in time and F (s) is the less familiar view in frequency. Everything about the signal is present in both views, but some things are easier to see in one view or the other. Using them together gives us a powerful tool for understanding systems and signals. You have already been using the Laplace transform without knowing it. For the system P (D)x = Q(D)f, (considering f to be the input and x the output) the transfer function Q(s)/P (s) is a Laplace transform of a function w(t). Over time we will give w(t) several diﬀerent names. To highlight its importance here we will call it the fundamental solution to the system. Also, just like the transfer function, the Laplace transform of any function has a pole diagram. In practice the Laplace transform has the following beneﬁts: • It makes explicit the long-term behavior of f (t). • The pole diagram of F (s) gives a succinct summary of some of the important prop- erties of f (t). • It allows us to easily compute the transfer function for LTI systems other than P (D)x = Q(D)f . In particular, it will do this for systems with delay. • Since it is the bridge between the time domain and the frequency domain we can credit it with all the beneﬁts of using transfer functions: – It allows us to analyze LTI systems, and in particular block diagrams, using simple algebra. – For the transfer function, when we restrict s by setting it equal to iω we get the frequency response of the system – The pole diagram of a transfer function can show at a glance the stability and frequency response of a system. It is an important engineering design tool. 1 18.031 The Laplace Transform 2 2 Deﬁnition of Laplace transform The Laplace transform of a function f (t) of a real variable t is another function depending on a new variable s, which is in general complex. We will denote the Laplace transform of f by Lf . It is deﬁned by the integral (Lf )(s) = ∫ ∞ 0− f (t)e −st dt, (1) for all values of s for which the integral converges. There are a few things to note. • Lf is only deﬁned for those values of s for which the improper integral on the right- hand side of (1) converges. • We will allow s to be complex. • The use of 0−, in the deﬁnition (1) is necessary to accomodate what we’ll call delta functions. Until we learn about such functions it will not be important. In those cases where 0− isn’t needed we will allow ourselves to use the less precise form (Lf )(s) = ∫ ∞ 0 f (t)e−st dt. (1′) • The limits of integration mean that the Laplace transform is only concerned with functions on (0−, ∞). What happens before time t = 0− does not play a role. 3 Notation, F (s) We will adopt the following conventions: 1. Writing (Lf )(s) can be cumbersome so we will often use an uppercase letter to indicate the Laplace transform of the corresponding lowercase function: (Lf )(s) = F (s), (Lg)(s) = G(s), etc. For example, in the formula (see the Laplace table) L(f ′) = sF (s) − f (0 −) it is understood that F (s) means L(f ). 2. Another notation we will use is L(f (t); s) 3. If our function doesn’t have a name we will use the formula instead. For example, the Laplace transform of the function t2 can written L(t2; s) or more simply L(t2). 4. If in some context we need to modify f (t), e.g. by applying a translation by a number a, we can write L(f (t − a); s) or L(f (t − a)) for the Laplace transform of f (t − a). 5. You’ve already seen several diﬀerent ways to use parentheses. Sometimes we will even drop them altogether. So, if f (t) = t2 then the following all mean the same thing (Lf ; s) = F (s) = Lf (s) = L(f (t); s) = L(t 2; s); Lf = F = L(t 2). 18.031 The Laplace Transform 3 4 Why s is called frequency The Laplace transform variable s is thought of as complex frequency. We alreadt saw this in the transfer function: if H(s) is the transfer function of an LTI system, then when s = iω we have H(s) = H(iω) is the complex gain of the system. A couple of other small points are in order here. The ﬁrst is that for the exponential est to make sense the exponent st must be dimensionless. Therefore the units of s must be 1/time, which are the same as the units of frequency. The second point is really a reiteration of what happens when we used complex replacement to ﬁnd the Sinusoidal Response Formula. Euler’s formula says eiωt = cos(ωt) + i sin(ωt) and we call ω the angular frequency. By analogy we call any exponent s in est a complex frequency. 5 First examples For the ﬁrst few examples we will explicitly use a limit for the improper integral. Soon we will do this implicitly without comment. Example 1. Let f (t) = 1, ﬁnd F (s) = Lf (s). answer: Using the deﬁnition (1′) we have L(1) = F (s) = ∫ ∞ 0 e−st dt = lim T →∞ e−st −s ]T 0 = lim T →∞ e−sT − 1 −s ]T 0 . The limit depends on whether the real part of s is positive or negative. lim T →∞ e −sT = { 0 if Re(s) > 0 ∞ if Re(s) < 0. Therefore, L(1) = F (s) = { 1 s if Re(s) > 0 diverges if Re(s) ≤ 0. (We didn’t actually compute the case Re(s) = 0, but it is easy to see it diverges.) Example 2. Compute L(eat). answer: Using the deﬁnition (1′) we have L(eat) = ∫ ∞ 0 eate−st dt = lim T →∞ e(a−s)t a − s ]T 0 = lim T →∞ e(a−s)T − 1 a − s ]T 0 . The limit depends on whether the real part of a − s is positive or negative. lim T →∞ e (a−s)T = { 0 if Re(s) > Re(a) ∞ if Re(s) < Re(a). Therefore, L(eat) = { 1 s−a if Re(s) > Re(a) diverges if Re(s) ≤ Re(a). 18.031 The Laplace Transform 4 (We didn’t actually compute the case Re(s) = Re(a), but it is easy to see it diverges.) We now have the ﬁrst two entries in our table of Laplace transforms: f (t) = 1 ⇒ F (s) = 1/s, Re(s) > 0 f (t) = eat ⇒ F (s) = 1/(s − a), Re(s) > Re(a). Note that the last ﬁeld in each line gives the range of s where the Laplace integral converges. 6 Linearity You will not be surprised to learn that the Laplace transform is linear. For functions f , g and constants c1, c2 L(c1f + c2g) = c1L(f ) + c2L(g) This is clear from the deﬁnition (1) of L because integration is linear. 7 Domain of F (s): complex s and the region of convergence As we’ve seen, we allow s to be complex and use, as needed, properties of the complex exponential. Example 3. Previously we saw that L(1) = 1/s, valid for all s with Re(s) > 0. The region Re(s) > 0 is called the region of convergence of the transform. It is a right half-plane in the complex s-plane. Re(s) > 0 Real axis Imag. axis Region of convergence: right half-plane Re(s) > 0. Likewise, the region of convergence for f (t) = eat is the right half-plane Re(s) > Re(a). We will see that the region of convergence for any function is a right half-plane. 7.1 The domain of F (s) For f (t) we have F (s) = 1/s with region of convergence Re(s) > 0. But, the function 1/s is well deﬁned for all s ̸= 0. So we can extend the domain of F (s) beyond the region of convergence to all s ̸= 0. The process of extending the domain of F (s) beyond the region of convergence is called analytic continuation. Though it has wider applicability: In this class analytic continu- ation will always consist of extending F (s) to the complex plane minus the zeros of the denominator. 18.031 The Laplace Transform 5 8 Functions of exponential order and piecewise continuous functions This is a technical section which assures us that the Laplace transform makes sense for all the functions we care about in 18.031 As we computed Laplace integrals we were careful to note for which values of s they con- verged. It can happen the integral does not converge for any value of s. In this case we say that the function fails to have a Laplace transform. Example 4. It is easy to see that f (t) = et2 has no Laplace transform. The problem is the et2 grows too fast as t gets large. 8.1 Functions of Exponential Order The class of functions that do have Laplace transforms are those of exponential order. We will see that every function of exponential order has a Laplace transform valid in a right half-plane Re(s) > a for some value a. A function is said to be of exponential order if there are numbers a and M such that |f (t)| < M eat. In this case, we say that f has exponential order a. We will give details below, but the basic idea is that in the Laplace integral the exponential decay of the e−st term will compensate for the growth of f (t) as long as f (t) grows slower than some exponential. Fortunately for us, all the functions we use in this class are of this type. Example 5. The functions 1, cos(ωt), sin(ωt), tn all have exponential order 0. The function eat has exponential order a. 8.2 Piecewise continuous functions A function f (t) is piecewise continuous if it is continuous everywhere except at a ﬁnite number of points in any ﬁnite interval and if at these points it has a jump discontinuity (i.e. a jump of ﬁnite height). Example 6. The square wave is piecewise continuous. t −3π −2π −π π 2π 3π The square wave is piecewise continuous. The main point of this section is the following theorem which assures us that the Laplace transform converges for all the functions we use in 18.031. Theorem: If f (t) is piecewise continuous and of exponential order a then the Laplace transform Lf (s) converges for all s with Re(s) > a. Proof: Suppose Re(s) > a, so s = (a + α) + ib for some positive α. We are given that 18.031 The Laplace Transform 6 |f (t)| < M eat. So, |f (t)e −st| = |f (t)e−(a+α)te−ibt| = |f (t)e −(a+α)t)| < M e ate−(a+α)t = M e−αt, Here, we have used that |e−ibt| = 1. Since ∫ ∞ 0 M e−αt dt converges for α > 0, the Laplace transform integral also converges. 9 Partial fractions and inverse Laplace transform In order to use the Laplace transform we need to be able to invert it and ﬁnd f (t) when we’re given F (s). Often this can be done by using the Laplace transform table. So for example, if F (s) = 1/(s − 5) then the table tells us that f (t) = e5t. More often we have to do some algebra to get F (s) into a form suitable for the direct use of the table. Our main technique for doing this is the partial fractions decomposition. You probably used partial fractions in calculus as a method for computing integrals. If you need to relearn this technique we have posted a note on it. The note includes a description of the Heaviside coverup method. This is a simple and extremely useful computing device. If you do not know it already you should read the ﬁrst section of the partial fraction note which explains it. 9.1 Laplace inverse by table lookup We’ve added a few functions to our table of Laplace transforms. Soon we will add some more. But right now we will learn to use the table to ﬁnd the inverse Laplace transform. We will illustrate this entirely by examples. Before we start you should open the copy of the table from the class website or else use the copy at the end of these notes. Notation: The inverse Laplace transform will be denoted L−1. Example 7. Find L−1(1/(s − 2)). answer: Use the table entry L(eat) = 1/(s − a): L −1(1/(s − 2)) = e2t. Example 8. Find L−1(1/(s2 + 9)). answer: Use the table entry L(sin(ωt)) = ω/(s2 + ω2) and linearity: L−1 ( 1 s2 + 9 ) = 1 3 L −1 ( 3 s2 + 32 ) = 1 3 sin(3t). Example 9. Find L−1(4/s2). answer: Use the table entry L(t) = 1/s2: L−1(4/s2) = 4t. Example 10. Find L−1(4/(s − 2)2). 18.031 The Laplace Transform 7 answer: We will use the s-shift formula L(eatf (t)) = F (s − a). In this case we take F (s) = 4/s2, which by Example 9 has f (t) = t. Therefore, L −1(4/(s − 2) 2) = L −1(F (s − 2)) = e2tf (t) = e 2t 4t. Example 11. Find L −1 ( 1 s2 + 4s + 13 ) . answer: We ﬁrst need to complete the square s 2 + 4s + 13 = s2 + 4s + 4 + 9 = (s + 2)2 + 9. We have a shifted function F (s + 2), where F (s) = 1/(s2 + 9). Using Example 8, we know that f (t) = sin(3t)/3, so using the s-shift rule we get L−1 ( 1 s2 + 4s + 13 ) = L −1(F (s + 2)) = e−2t sin(3t) 3 . (Note that L(ω/((s − a)2 + ω2)) = eat sin(ωt) is in the Laplace table, so we could have done this example directly.) Example 12. Find L −1 ( s (s2 + ω2)2 ) . answer: We haven’t seen this formula yet, but there is a table entry, which gives: t 2ω sin(ωt). Example 13. Find L−1 ( 1 (s2+ω2)2 ). answer: This is also a table entry, answer: 1 2ω3 (sin(ωt) − ωt cos(ωt)). 10 More entries for the Laplace table In this section we will add some new entries to our table of Laplace transforms. Note: posted on the class website is the complete Laplace table that we will need in this class. For convenience it is also appended at the end of these notes. 10.1 Laplace transform of sine and cosine 1. L(cos(ωt)) = s s2 + ω2 , with region of convergence Re(s) > 0. 2. L(sin(ωt)) = ω s2 + ω2 , with region of convergence Re(s) > 0. Proof: We know that cos(ωt) = eiωt + e−iωt 2 , and sin(ωt) = eiωt − e−iωt 2i 18.031 The Laplace Transform 8 (These formulas are extremely useful, if they are not immediately familiar you should take a moment to understand them. You can prove them by expanding each of the exponentials into cos() + i sin().) We already know that L(eat) = 1/(s − a). Using this and the formulas above, we obtain L(cos(ωt) = L ( eiωt + e−iωt 2 ) = 1 2 ( 1 s − iω + 1 s + iω ) = s s2 + ω2 L(sin(ωt) = L ( eiωt − e−iωt 2i ) = 1 2i ( 1 s − iω − 1 s + iω ) = ω s2 + ω2 The region of convergence follows from the fact that cos(ωt) and sin(ωt) both have expo- nential order 0. Another approach would have been to use integration by parts to compute the transforms directly from the Laplace integral. 10.2 Laplace transform of derivatives 10.3 t-derivative rule This course makes heavy use of diﬀerential equations, so we should try to compute L(f ′). (We use the notation f ′ instead of ˙f simply because we think the dot does not sit nicely over the tall letter f .) As usual, we write L(f ; s) = F (s). The t-derivative rule is L(f ′) = sF (s) − f (0 −) (2) L(f ′′) = s2F (s) − sf (0 −) − f ′(0 −) (3) L(f (n)) = snF (s) − sn−1f (0 −) − sn−2f ′(0 −) + . . . + f (n−1)(0 −). (4) Technically we need to assume that f (t) has exponential order a and Re(s) > a. With this assumption e−stf (t) is 0 when t = ∞. Proof: Rule (2) is a simple consequence of the deﬁnition of Laplace transform and inte- gration by parts. The integration by parts formula is ∫ uv′ dt = uv − ∫ u ′v dt. We’ll use this with u = e−st and v′ = f ′(t), so that u′ = −se−st and v = f (t). Now, by deﬁnition L(f ′) = ∫ ∞ 0− f ′(t)e−st dt. We start by writing the deﬁnition of L(f ′) and then we apply integration by parts: L(f ′) = ∫ ∞ 0− f ′(t)e−st dt = f (t)e −st]∞ 0− + s ∫ ∞ 0− f (t)e−st dt = −f (0 −) + s ∫ ∞ 0− f (t)e −st dt The last equality follows from our assumption that f (t)e−st is 0 at t = ∞. Now notice that the integral in the expression at the right is none other than sF (s). Thus we have proved the t-derivative law L(f ′) = sF (s) − f (0−). 18.031 The Laplace Transform 9 Rule (3) follows by applying rule (2) twice. L(f ′′) = sL(f ′) − f ′(0 −) = s(sL(f ) − f (0 −)) − f ′(0 −) = s2F (s) − sf (0 −) − f ′(0 −). Rule (4) Follows by applying rule (2) n times. Notes: 1. Calculations will be easiest when f (0−) = 0, f ′(0−) = 0, etc. We will call this rest initial conditions. 2. A good way to think of the t-derivative rules is L(f ) = F (s) L(f ′) = sF (s) + terms at 0−. L(f ′′) = s 2F (s) + terms at 0−. Roughly speaking, Laplace transforms diﬀerentiation in t to multiplication by s. Example 14. Let f (t) = eat. We can compute L(f ′) in two ways: directly and by using rule (2). Let’s compute both ways and check that they give the same answer. Directly: f ′(t) = aeat ⇒ L(f ′) = a/(s − a). Rule (2): L(f ) = F (s) = 1/(s − a) ⇒ L(f ′) = sF (s) − f (0−) = s/(s − a) − 1 = a/(s − a). Both methods give the same answer. Example 15. Let f (t) = t2+2t+1. Compute L(f ′′) both directly and using the t-derivative rule. answer: Directly: f ′′(t) = 2 ⇒ L(f ′′) = 2/s. Using rule (4): L(f ′′) = s2F (s) − sf (0−) − f ′(0−) = s2(2/s3 + 2/s2 + 1/s) − s · 1 − 2 = 2/s. Both methods give the same answer. 11 s-derivative rule There is a certain symmetry in our formulas. If derivatives in time lead to multiplication by s then multiplication by t should lead to derivatives in s. This is true, but, as usual, there are small diﬀerences in the details of the formulas. The s-derivative rule is L(tf ; s) = −F ′(s) (5) L(tnf ; s) = (−1) nF (n)(s). (6) 18.031 The Laplace Transform 10 Proof: Rule (5) is a simple consequence of the deﬁnition of Laplace transform. F (s) = L(f ) = ∫ ∞ 0− f (t)e −st dt ⇒ F ′(s) = d ds ∫ ∞ 0− f (t)e −st dt = ∫ ∞ 0− −tf (t)e−st = −L(tf (t)). Rule (6) is just rule (5) applied n times. 11.1 Powers of t and repeated factors in s Now that we have the derivative rules we can use them to avoid having to compute a number of integrals. We derive more formulas for our Laplace table in a series of examples. Example 16. Use the s-derivative rule to ﬁnd L(t), L(t2), etc. answer: Start with f (t) = 1, then F (s) = 1/s. The s-derivative rule now says L(t) = −F ′(s) = 1/s2 Using L(t) = 1/s2 we get L(t2) = L(t · t) = − dL(t) ds = −(1/s2)′ = 2/s3. Continuing we get L(t3) = −(2/s3)′ = 3 · 2/s4. In general, we have L(tn) = n!/sn+1. Notes: 1. You should check that this rule gives the correct answer when n = 1 2. The region of convergence for L(tn) is the same as for L(1), i.e. when Re(s) > 0. The easiest way to see this is to notice that multiplying by powers of t does not change the exponential order of a function. Example 17. Use the s-derivative rule to ﬁnd L(teat) and L(tneat). answer: Start with f (t) = eat, then F (s) = 1/(s − a). The s-derivative rule now says L(teat) = −F ′(s) = 1/(s − a)2. Continuing: L(t 2eat) = F ′′(s) = 2/(s − a) 3 L(t 3eat) = −F ′′′(s) = 3 · 2/(s − a) 4 L(t 4eat) = F (4)(s) = 4 · 3 · 2/(s − a)5 . . . L(t neat) = (−1) nF (n)(s) = n!/(s − a)n+1. 18.031 The Laplace Transform 11 11.2 Repeated quadratic factors Look at the table entries for repeated quadratic factors L ( 1 2ω3 (sin(ωt) − ωt cos(ωt)) ) = 1 (s2 + ω2)2 (7) L ( t 2ω sin(ωt) ) = s (s2 + ω2)2 (8) L ( 1 2ω (sin(ωt) + ωt cos(ωt)) ) = s2 (s2 + ω2)2 (9) Let’s prove them using the s-derivative rule. Proof of (8). Let f (t) = sin(ωt). We know that F (s) = ω s2 + ω2 , so the s-derivative rule implies L(t sin ωt) = −F ′(s) = 2ωs (s2 + ω2)2 . This is the same as formula (8) except the factor of 2ω is moved from one side to the other. The other two formulas can be proved in a similar fashion. We won’t give the proofs here. 11.3 s-shift formula If a is any complex number and f (t) is any function then the s-shift formula is L(eatf (t)) = F (s − a). Proof. As usual we write F (s) = L(f ; s). If the region of convergence for L(f ) is Re(s) > a then the region of convergence for L(eatf (t)) is Re(s) > Re(a) + a. Now we simply calculate directly from the deﬁnition of Laplace transform: L(e atf (t)) = ∫ ∞ 0 eatf (t)e−st dt = ∫ ∞ 0 f (t)e−(s−a)t dt = F (s − a). Example 18. Find the Laplace transform of e−t cos(3t). answer: Since L(cos(3t)) = s/(s2 + 9) the s-shift formula gives L(e−t cos(3t) = s + 1 (s + 1)2 + 9 . Note: we could do this almost as easily by using Euler’s formula to write e −t cos(3t) = (1/2) (e(−1+3i)t + e(−1−3i)t) . We record here two important cases of the s-shift formula: L(e at cos(ωt)) = s − z (s − a)2 + ω2 L(e at sin(ωt)) = ω (s − a)2 + ω2 . 18.031 The Laplace Transform 12 Consistency. It is a good exercise to check for consistency among our various formulas: 1. We have L(1) = 1/s, so the s-shift formula gives L(eat · 1) = 1/(s − a). This matches our formula for L(eat). 2. We have L(tn) = n!/sn+1. If n = 0 we have L(t0) = 0!/s = 1/s. This matches our formula for L(1). 12 Laplace: solving initial value problems 12.1 Introduction We now have everything we need to solve initial value problems using the Laplace transform. We will show how to do this through a series of examples. To be honest we should admit that some initial value problems are more easily solved by other techniques. However, there are cases where the Laplace machinery can help keep things straight. 12.2 Examples of solving initial value problems (IVPs) Example 19. Solve ˙x + 3x = e−t with rest initial conditions (rest IC). answer: Rest IC mean that x(t) = 0 for t < 0, so x(0−), ˙x(0−), . . . are all 0. As usual, we let X = L(x). Using the t-derivative rule we can take the Laplace transform of (both sides) of the DE. (sX(s) − x(0 −)) + 3X(s) = 1/(s + 1). Next we substitute the known value x(0−) = 0 and solve for X(s) (s + 3)X(s) = 1 s + 1 ⇒ X(s) = 1 (s + 1)(s + 3) . (10) Finally, we ﬁnd x(t) = L−1(X) by using cover-up to do the partial fractions decomposition. X(s) = 1 (s + 1)(s + 3) = 1/2 s + 1 − 1/2 s + 3 , thus x(t) = 1 2 e−t − 1 2 e−3t for t > 0. Notes: 1. The term e−t/2 is what the exponential response formula would give us. The term e−3t/2 is the homogenous part of the solution, needed to match the IC. 2. This technique found x(t) for t > 0. The rest IC tell us x(t) = 0 for t < 0. 3. The factor of 1/(s + 3) in the expression for X(s) in (10) is none other than the transfer function of the system: ˙x + 3x = f (t). Example 20. Solve ˙x + 3x = e−t, x(0−) = 4. answer: Laplace: sX(x) − x(0 −) + 3X(s) = 1/(s + 1) ⇒ (s + 3)X(s) = 4 + 1/(s + 1). 18.031 The Laplace Transform 13 Solve for X(s): X(s) = 4 s + 3 + 1 (s + 1)(s + 3) (11) We can use the partial fractions work from Example 19. x(t) = 4e −3t + 1 2 e −t − 1 2 e−3t for t > 0 = 1 2 e −t + 7 2 e −3t for t > 0. Notes: (Same remarks as in the previous example.) Example 21. Solve ˙x + 2x = 4t, with initial condition x(0−) = 1. answer: Taking the Laplace transform of the equation: sX − x(0−) + 2X = 4/s2. Therefore, X(s) = 4 s2(s + 2) + 1 s + 2 = A s + B s2 + C s + 2 + 1 s + 2 . Therefore the inverse Laplace transform gives us x(t) = A + Bt + Ce −2t + e −2t, for t > 0. The coverup method gets us B = 2, C = 1. Some algebra (undetermined coeﬃcients) gives A = −1. Finally we record the exact solution: x(t) = −1 + 2t + 2e−2t, for t > 0. Example 22. Solve ¨x + 4x = cos(2t), with rest initial conditions answer: Laplace: (s2 + 4)X(s) = s/(s2 + 4) ⇒ X(s) = s/(s2 + 4)2. This is a repeated quadratic factor and it is in our table: x(t) = t sin(2t)/4. Notes: 1. This is a response of pure resonance. 2. We could have turned the logic around and used our previous knowledge of the solution to this equation to give yet another proof for the table entry L(t sin(ωt)/2ω) = s/(s2 + ω2)2. 13 The transfer function Consider the system with input f (t) and response x: P (D)x = Q(D)f. In class we deﬁned the transfer function as Q(s)/P (s). This arose for us as when we tried solving the above system with input f (t) = est. In that case, the Exponential Response Formula gave us a particular solution x(t) = (Q(s)/P (s))est. Now that we have the Laplace transform we will see how it gives us the transfer function naturally and for arbitrary f . Problem. Use the Laplace transform to solve the equation P (D)x = Q(D)f starting with rest initial conditions. 18.031 The Laplace Transform 14 answer: Let X = L(x) and F = L(f ). Since we start from rest there are no 0− terms, so we get P (s)X(s) = Q(s)F (s), or equivalently X(s) = P (s) Q(s) F (s). (12) There we have it! Viewed in the frequency domain, the output is simply the transfer function times the input. We could say that the transfer function ‘transfers’ the input to the output. Another standard way of saying this is transfer function = output input . Be sure to recognize that this is all taking place on the frequency side. Also be sure to marvel at the fact that from this side the output/input always gives the same function. Here’s a summary of what we have: 1. For the system P (D)x = Q(D)f the transfer function is W (s) = Q(s)/P (s). 2. In the frequency domain, solving for X with rest initial conditions is purely algebraic: X(s) = W (S)F (s). 14 Block diagrams 14.1 Introduction We already discussed some simple block diagrams when we introduced the notions of system, input, and output. Here, we will look at systems with more complicated block diagrams and show how to use them to compute the transfer functions. As we do this, it will be useful to keep in mind the desciption of the transfer function as multiplying the input to get the output. 14.2 Simple examples Example 23. Suppose we have the system m¨x+b ˙x+kx = f (t), with input f (t) and output x(t). The Laplace transform converts this to functions and equations in the frequency variable s: X(s) = 1 ms2 + bs + k F (s). The transfer function for this system is W (s) = 1/(ms2 + bs + k), and we can write the relation between input and output as input F (s) ⇝ output X(s) = W (s)F (s) As a block diagram we can represent the system by F (s) W (s) X(s) Block diagram for a system with transfer function W (s). 18.031 The Laplace Transform 15 Sometimes we write the formula for the transfer function in the box representing the system. For the above example this would look like F (s) 1 ms2 + bs + k X(s) Block diagram giving the formula for the transfer function. Example 24. (Cascading systems) Consider the cascaded system P1(D)x = Q1(D)f, P2(D)y = Q2(D)x, rest IC. The input to the cascade is f and the output is y. That is, the ﬁrst equation takes the input f and outputs x. Then x is the input to the second equation, which ouputs y. This is easy to solve on the frequency side. Let W1(s) = Q1(s)/P1(s) and W2(s) = Q2(s)/P2(s) be the transfer functions for the two diﬀerential equations. Considering the two equations separately we have X(s) = W1(s) · F (s) and Y (s) = W2(s) · X(s). It follows immediately that Y (s) = W2(s) · W1(s) · F (s). Therefore the transfer function for the cascade is output/input = Y (s)/F (s) = W2(s) · W1(s). In other words, for cascaded systems the transfer functions multiply. Representing this as block diagrams we have two equivalent diagrams W1(s) W2(s) F (s) X(s) Y (s) W1(s)W2(s) Y (s)F (s) Equivalent block diagrams for a cascaded system. Example 25. (Parallel systems) Suppose that we have a system consisting of two systems in parallel as shown in the block diagram. W1(s) W2(s) + F (s) Y (s) Systems in parallel. Find the transfer function for the entire system. answer: The plus sign in the circle indicates the two signals coming into the junction should be added. The split near the start indicates the same input F (s) is sent into each system. The way to ﬁgure out the transfer function is to name the outputs of each individual system. 18.031 The Laplace Transform 16 W1(s) W2(s) + F (s) F F X1 X2 Y (s) System with intermediate outputs labeled. For each system we know output = transfer function × input. Thus, X1 = W1 · F , X2 = W2 · F , Y = X1 + X2. So, we easily compute Y = X1 + X2 = W1 · F + W2 · F = (W1 + W2) · F. Therefore the transfer function is W1 + W2. Example 26. An example of a parallel system is several microphones feeding the same sound into a mixing desk which in turn feeds an ampliﬁer and speaker system. 14.3 Feedback loops Many systems are best described with feedback loops. In a broad sense, in a feedback loop the output is used to modify the input which in turn produces the output. In feedback control, the output of the system is monitored and used to modify the input in such a way as to ultimately produce a desired output. It is very hard to control a system without a feedback loop. For example, imagine trying to walk without sensory feedback about your surroundings. For most people, just shutting their eyes makes it hard to stand on one foot for very long. Block diagrams are an excellent way to describe feedback. Suppose we start with a system with transfer function W (s). F (s) W (s) X(s) and modify it to have the feedback loop shown in the next ﬁgure. ∑ W ×g + − F V Y gY The original system is known as the open loop system and the corresponding system with feedback is known as the closed loop system. We’ve labeled the outputs from each system element. The symbol for the system element indicates what it does to its input(s). The symbol ×g means the input to that element is scaled by g, that is apply a gain of g to the input. The symbol ∑ means the two inputs are combined; the plus and minus signs indicate whether to add or subtract the corresponding input. The method of ﬁnding the transfer function is the same as in the previous examples. A bit of algebra gives V = F − gY, Y = W · V ⇒ Y = W (F − gY ) ⇒ Y = W 1 + gW · F. 18.031 The Laplace Transform 17 As usual, the transfer function is output/input = Y /F = W/(1 + gW ). This formula is one case of what is often called Black’s formula. Example 27. Suppose we have an open loop system, say a circuit, with transfer function W (s) = s/(as2 + bs + c). If we add a feedback loop with gain g then using Black’s formula the closed loop transfer function is s/(as2 + bs + c) 1 + gs/(as2 + bs + c) = s as2 + (b + g)s + c . Example 28. Feedback can turn an unstable system into a stable one. Consider the open loop system with transfer function 1/(s − 1). F (s) 1 s − 1 X(s) This has a pole at s = 1, so it is unstable. Find all the values of a constant gain g that make the closed loop system stable. ∑ 1 s − 1 ×g + − F V Y gY answer: Black’s formula tells us that the closed loop transfer function is 1/(s − 1) 1 + g/(s − 1) = 1 s − 1 + g . Thus the closed loop system has one pole and it’s at 1 − g. As long as g > 1 this pole is negative and the closed loop system is stable. Note. The opposite is also true: feedback can make a stable system unstable. 15 Stability of a function In this discussion of stability we will assume L(f ) is a rational function. It is possible to deal with time shifted functions, but it would unduly complicate the presentation, so in this section we will assume that all functions have a Laplace transform of the form F (s) = Q(s)/P (s). 15.1 Deﬁnition of stability for a function We say that a function is exponentially stable if it goes to zero faster than some decaying exponential. Formally: f (t) is exponentially stable if it is of negative exponential order, i.e. if |f (t)| < M e −at for some positive M and a. Exponential stability is equivalent to all the poles of f have negative real part. 18.031 The Laplace Transform 18 For a rational function F (s) = Q(s)/P (s) a pole is called simple if it is not a repeated root of P (s). If all the poles have negative real part except for at least one simple pole with zero real part, then we say that f (t) is marginally stable. In this case, f (t) may not decay to 0, but it stays bounded. Example 29. The functions e−3t, e−3t cos(5t), t3e−2t are all exponentially stable. Example 30. The functions cos(t), 1, e−2t + 1 are all marginally stable Example 31. The function t sin(ωt) has a double pole at s = iω. It is not stable or marginally stable and it is not bounded as t gets large. Example 32. The function e2t has a pole at s = 2. It is not bounded and not stable. 15.2 The ﬁnal value theorem We are often interested in the long term behavior of a system response. If we are working in the frequency domain it helps to have a way of determining the long term behavior directly from the Laplace transform of a function. The next theorem is useful in this regard. Theorem. Final value theorem. Let f (t) be a function and F (s) = L(f ). If all the poles of sF (s) have negative real part then lim t→∞ f (t) = lim s→0 sF (s). An equivalent way of stating the criterion is that all the poles of F (s) have negative real part except for possibly a simple pole at s = 0. Proof. Rather than give a formal proof we will indicate an easy way to understand this theorem. The criterion that the poles of sF (s) have negative real part means that the partial fraction decomposition of F (s) is of the form F (s) = A s + B1 s + a1 + B2 s + a2 + . . . + C1 (s + a1)2 + . . . + D1 (s + a1)3 + . . . , where Re(aj) < 0. This means that f (t) has the form f (t) = A + B1e−a1t + B2e−a2t + . . . + C1te−a1t + . . . + D1t 2e −a1t + . . . Only the ﬁrst of these terms does not go to 0 as t grows large. That is, lim t→∞ f (t) = A. (13) On the frequency side we have sF (s) = A + B1s s + a1 + B2s s + a2 + . . . C1s (s + a1)2 + . . . , D1s (s + a)3 + . . . , Only the ﬁrst of these terms does not go to 0 as s goes to 0. That is, lim s→0 sF (s) = A. (14) Taken together Equations 13 and 14 prove the ﬁnal value theorem. 18.031 The Laplace Transform 19 Example 33. The function f (t) = 2 + e−3t + te−5t has Laplace transform F (s) = 2/s + 1/(s + 3) + 1/(s + 5)2. It has simple poles at s = 0 and s = −3 and a double pole at s = −5. If satisﬁes the criterion of the ﬁnal value theorem and we can check: lim t→∞ f (t) = lim t→∞ 2 + e −3t + te−5t = 2 and lim s→0 sF (s) = lim s→0 2 + s s + 3 + s (s + 5)2 = 2. Thus we have veriﬁed the theorem in this case. Example 34. The function f (t) = 2 + e−3t + e5t has Laplace transform F (s) = 2/s + 1/(s + 3) + 1/(s − 5). It has simple poles at s = 0, s = −3 and s = 5. Because one of its poles is positive it does not satisﬁes the criterion of the ﬁnal value theorem. Checking the two limits: lim t→∞ f (t) = lim t→∞ 2 + e −3t + e5t = ∞ and lim s→0 sF (s) = lim s→0 2 + s s + 3 + s s − 5 = 2. We see the limits are not the same! This shows us a valuable lesson: Lesson. You must check that the hypothesis of the ﬁnal theorem hold, otherwise you can get a misleading result. Here’s another example showing this lesson. Example 35. The function f (t) = sin(2t) has Laplace transform F (s) = 2/(s2 + 4). It has simple poles at s = ±2i. These poles do not satisy the criterion of the ﬁnal value theorem and we see lim t→∞ f (t) = lim t→∞ sin(2t) does not exist and lim s→0 sF (s) = lim s→0 s s2 + 4 = 0. Again, the limits are not the same, but this does not violate the ﬁnal value theorem because it does not apply to this case. A good example of the use of the ﬁnal value theorem is in the note on PID controllers posted on the class website. Laplace Transform Table 18.031, January 2015 Properties and Rules Function Transform f (t) F (s) = ∫ ∞ 0− f (t)e−st dt (Deﬁnition) a f (t) + b g(t) a F (s) + b G(s) (Linearity) eatf (t) F (s − a) (s-shift) f ′(t) sF (s) − f (0 −) f ′′(t) s2F (s) − sf (0 −) − f ′(0 −) f (n)(t) snF (s) − sn−1f (0 −)− · · · − f (n−1)(0 −) tf (t) −F ′(s) t nf (t) (−1) nF (n)(s) u(t − a)f (t − a) e−asF (s) (t-translation or t-shift) u(t − a)f (t) e−asL(f (t + a)) (t-translation) (f ∗ g)(t) = ∫ t+ 0− f (t − τ ) g(τ ) dτ F (s) G(s) ∫ t+ 0− f (τ ) dτ F (s) s (integration rule) Interesting, but not included in this course. f (t) t ∫ ∞ s F (σ) dσ (The function table is on the next page.) 1 Laplace Table, 18.031 2 Function Table Function Transform Region of convergence 1 1/s Re(s) > 0 e at 1/(s − a) Re(s) > Re(a) t 1/s 2 Re(s) > 0 t n n!/s n+1 Re(s) > 0 cos(ωt) s/(s2 + ω2) Re(s) > 0 sin(ωt) ω/(s2 + ω2) Re(s) > 0 e at cos(ωt) (s − a)/((s − a)2 + ω2) Re(s) > Re(a) e at sin(ωt) ω/((s − a) 2 + ω2) Re(s) > Re(a) δ(t) 1 all s δ(t − a) e−as all s cosh(kt) = ekt + e −kt 2 s/(s2 − k2) Re(s) > k sinh(kt) = e kt − e −kt 2 k/(s2 − k2) Re(s) > k 1 2ω3 (sin(ωt) − ωt cos(ωt)) 1 (s2 + ω2)2 Re(s) > 0 t 2ω sin(ωt) s (s2 + ω2)2 Re(s) > 0 1 2ω (sin(ωt) + ωt cos(ωt)) s2 (s2 + ω2)2 Re(s) > 0 u(t − a) e−as/s Re(s) > 0 t neat n!/(s − a) n+1 Re(s) > Re(a) Interesting, but not included in this course. 1 √ π t 1 √s Re(s) > 0 t a Γ(a + 1) sa+1 Re(s) > 0","libVersion":"0.3.1","langs":""}