{"path":"iCloudDrive/bks/Combinatorics/Combinatorics/Probabilistic Method - Po-Shen Loh - MOP 2010.pdf","text":"The Probabilistic Method Po-Shen Loh June 2010 1 Warm-up 1. (Russia 1996/4) In the Duma there are 1600 delegates, who have formed 16000 committees of 80 persons each. Prove that one can ﬁnd two committees having at least four common members. Solution: Simply select a random 2-set of committees. Calculate expected number of people in both committees, and use convexity of ∑ x 2 i ≥ n(avg)2. 2. (Iran Team Selection Test 2008/6) Suppose 799 teams participate in a tournament in which every pair of teams plays against each other exactly once. Prove that there exist two disjoint groups A and B of 7 teams each such that every team from A defeated every team from B. Solution: Sample A as a random 7-set. Let X be the number of guys that are totally dominated by A. Letting d− v denote the in-degree of v, we have E [X] = ∑ v (d− v 7 )/(799 7 ). But ∑ v d− v = (799 2 ), which means that the average in-degree is exactly 399. By convexity, E [X] ≥ 799 · (399 7 )/ (799 7 ) ≈ 800 · (1/2) 7 ≈ 6.25, which is enough since X is an integer. Pick 7 teams B from the dominated group. 2 Linearity of expectation Deﬁnition. Let X be a random variable which takes values in some ﬁnite set S. Then the expected value of X, denoted E [X], is: E [X] = ∑ x∈S x · P [X = x] Use the following exercises to get used to the concept of expected value. 1. What is the expected number of heads in 101 tosses of a fair coin? Prove this formally from the deﬁnition. Solution: 101∑ i=0 i (101 i ) 1 2101 = 2 −101 101∑ i=1 i · 101 i ( 100 i − 1 ) = 2 −101 100∑ j=0 101(100 j ) = 2 −101 · 101 · 2 100 = 101/2. 2. What is the expected number of heads in 1 toss of a coin which lands heads with probability 1/10? 3. Can you calculate the expected number of heads in 101 tosses of a coin which lands heads with probability 1/10? One of the most useful facts about the expected value is that if X and Y are random variables, not necessarily independent, then E [X + Y ] = E [X] + E [Y ]. This is known as linearity of expectation. Now use that fact to solve the following problems. 1 1. Calculate the expected number of heads in 101 tosses of a coin which lands heads with probability 1/10. Solution: This is the sum of 101 random variables, each of which has expectation 1/10. 2.1 That’s nice, but how does this solve combinatorics problems? The key lemma is the following apparently trivial result. Lemma. Let X be a random variable. Then there is some point in the probability space where X ≥ E [X], and also some point in the probability space where X ≤ E [X]. This takes the place of the “prove-by-contradiction” approach common in many counting-in-two-ways arguments. But where can probability arise in an apparently deterministic combinatorial problem? Let us illustrate this by reworking one of the Warm-up problems. Solution. Sample a pair of committees uniformly at random (i.e., randomly pick one of the (16000 2 ) possible pairs). Let X be the number of people who are in both chosen committees. Note that X = X1 + · · · + X1600, where each Xi is the {0, 1}-random variable telling whether the i-th person was in both chosen committees. By linearity of expectation, E [X] = E [X1] + · · · + E [X1600] . The magic is that each E [Xi] is easy to calculate! Let ni be the number of committees that the i-th person belongs to. Then, each E [Xi] = P [i-th person is in both picked committees] = (ni 2 )/ (16000 2 ). The only piece of information we know about the {ni} is that their sum ∑ i ni = 16000 · 80, so this suggests that we use convexity to bound E [X] in terms of the average of {ni}, which we denote by n = (16000 · 80)/1600 = 800: E [X] ≥ 1600 · (n 2 ) /( 16000 2 ) = 1600 · ( 800 2 )/ (16000 2 ) = 1600 · 800 · 799 16000 · 15999 = 3.995. (One could see that since 799 ≈ 800 and 15999 ≈ 16000, the last fraction is roughly 1/400.) But by the Lemma, we know that some outcome of the probabilistic sampling produces an X ≥ 3.995. Since X is always an integer, that outcome must in fact have X ≥ 4. In particular, we conclude that some pair of committees has ≥ 4 common members. □ Remarks. Observe that once we decided to select the pair of committees at random, we could essentially “follow our nose” to ﬁnish the rest of the argument. In particular, we were led to apply convexity because that was the only way to proceed, given our information. Even more conveniently, the sharpening from 3.995 to 4 was automatic! 3 Olympiad problems 1. In a 100 × 100 array, each of the numbers 1, 2, . . . , 100 appears exactly 100 times. Show that there is a row or a column in the array with at least 10 distinct numbers. Solution: Let n = 100. Choose a random row or column (2n choices). Let X be the number of distinct entries in it. Now X = ∑ Ii, where each Ii is the indicator variable of i appearing (possibly more than once) in our random row or column. Clearly, each E [Ii] = P [Ii ≥ 1]. To lower-bound this, observe that the worst-case is if all n appearances of i are in some √n × √n submatrix, which gives P [Ii ≥ 1] ≥ 2 √n/(2n) = 1/ √n. Hence by linearity, E [X] ≥ √n. 2. (Russia, 1999.) In a class, each boy is friends with at least one girl. Show that there exists a group of at least half of the students, such that each boy in the group is friends with an odd number of the girls in the group. 2 Solution: Choose girls independently with probability 1/2, and then let the set of boys be all of those who have an odd number of friends in the girl group. Let X be the number of boys and girls selected, and break this into the sum of indicators. For each girl, obviously the indicator adds 1/2 to the sum. For each boy, the probability that he joins is precisely the probability that Bin [k, 1/2] is odd, where k was the number of girls he knew. To see that this probability is 1/2, note that it is the parity of the sum of k independent coin ﬂips. In particular, the ﬁnal ﬂip independently ﬂips or retains the ﬁnal parity, hence odd with probability 1/2. 3. (IMO Shortlist 1999/C4) Let A be any set of n residues mod n2. Show that there is a set B of n residues mod n2 such that at least half of the residues mod n2 can be written as a + b with a ∈ A and b ∈ B. Solution: Make n independent uniformly random choices from the n2 residues, and collect them into a set B. Note that since we use independence, this ﬁnal set may have size < n. But if we still have A + B occupying at least half of the residues, then this is okay (we could arbitrarily augment B to have the full size n). Let X be the number of residues achievable as a + b. For each potential residue i, there are exactly n ways to choose some b for which A + b ∋ i, since |A| = n. Therefore, the probability that a given residue i appears in A + B is precisely 1 − (1 − n n2 )n. Then E [X] is exactly n2 times that, because there are n2 total residues. Hence it suﬃces to show that 1 − (1 − n n2 )n ≥ 1/2. But this follows from the bound 1 − 1 n ≤ e−1/n, using e ≈ 2.718. 4. (MOP 2010.) Let G be a d-regular graph. Prove that for every k ≤ d, there is a Kk+1-free induced subgraph on at least kn d+1 vertices. Solution: Color with d + 1 colors. Take k biggest color classes, which by averaging is at least k times the average. 5. For every integer k, can you construct a graph which requires k colors to properly color, but has average degree equal to 1? Solution: Take Kk, giving sum of degrees k(k − 1) = k2 − k on k vertices. Then add k2 − 2k more isolated vertices to get average degree 1. 6. (MOP 2010, what should have been asked.) Let G be a graph with average degree d. Prove that for every k ≤ d, there is a Kk+1-free induced subgraph on at least kn d+1 vertices. Solution: Randomly permute the vertices. Use the greedy algorithm, taking each vertex if it can be added without making any Kk+1. Observe that we will actually take every vertex v with the property that the permutation induced on {v} ∪ N (v) has v in position 1 . . . k. (We might also take more.) This is because v would only have degree at most k − 1 back to the previously selected guys, making at most a Kk. Now the expected size of the selected set is at least ∑ v k dv + 1 ≥ n · k d + 1 . 4 Famous results These are interesting results from research mathematics (as opposed to Olympiad mathematics) that have very elegant probabilistic proofs. They come from the excellent book titled The Probabilistic Method, by Noga Alon and Joel Spencer. 1. (Erd˝os-Ko-Rado Theorem) Let n ≥ 2k be positive integers, and let C be a collection of pairwise- intersecting k-element subsets of {1, . . . , n}, i.e., every A, B ∈ C has A ∩ B ̸= ∅. Prove that |C| ≤ (n−1 k−1). Remark: this corresponds to the construction which takes all subsets that contain the element 1, say. 3 Solution: Pick a random k-set A from 2[n] by ﬁrst selecting a random permutation σ ∈ Sn, and then picking a random index i ∈ [n]. Then deﬁne A = {σ(i), . . . , σ(i + k − 1)}, with indices after n wrapping around, of course. It suﬃces to show that P [A ∈ C] ≤ k/n. Let us show that conditioned on any ﬁxed σ, P [A ∈ C|σ] ≤ k/n, which will ﬁnish our problem. But this is equivalent to the statement that C can only contain ≤ k intervals (wrapping after n) of the form {i, . . . , i + k − 1}, which is easy to show. 2. (Sperner’s Lemma) Prove that the maximum antichain in 2[n] has size ( n ⌊n/2⌋). That is, show that if F is a collection of subsets of {1, . . . , n} such that no two distinct sets A, B ∈ F satisfy A ⊂ B, then |F| ≤ ( n ⌊n/2⌋). Solution: The idea is given as a hint in Alon-Spencer. Take a random permutation σ and let the random variable X = #{i : σ(1), . . . , σ(i) ∈ F}. Consider E [X]. By deﬁnition of F, X is bounded by 1, and the events {σ(1), . . . , σ(K)} ∈ F are disjoint for distinct K. Let Nk be the number of subsets of size k in F. E [X] = n∑ k=1 P [{σ(1), . . . , σ(k)} ∈ F] = n∑ k=1 Nk(n k) ≥ n∑ k=1 Nk( n ⌊n/2⌋) . Since E [X] ≤ 1, we conclude that ∑ Nk is bounded by ( n ⌊n/2⌋), and we are done. 3. (Crossing Lemma) No matter how you draw a graph with V vertices and E edges in the plane, there will be ≥ E3 64V 2 pairs of crossing edges, as long as E ≥ 4V . Solution: Since planar graphs have E ≤ 3V − 6, we automatically ﬁnd that the crossing number is always ≥ E − (3V − 6) > E − 3V . Now take a drawing with, say, t crossings, and sample vertices randomly with probability p. V goes down to pV , E goes down to p 2E, and cr goes down to p4t. But this new drawing needs to satisfy the above, so p4t > p 2E − 3pV. Substituting p = 4V /E, we get the desired result. 4. (Bollob´as, 1965) Let A1, . . . , An and B1, . . . , Bn be distinct subsets of N such that: • every |Ai| = r and every |Bi| = s, • for every i, Ai ∩ Bi = ∅, and • for every i ̸= j, Ai ∩ Bj ̸= ∅. Prove that n ≤ (r+s r ). Solution: (Proof from Alon-Spencer.) Let the universe X be the union of all Ai and Bj. Take random permutation of X. Deﬁne event Xi to be that all elements of Ai precede all elements of Bi in permutation. Easy to check that all n of the events Xi are pairwise disjoint, and each P [Xi] = (r+s r )−1. But sum of probabilities is ≤ 1, so done. 5. (Lov´asz, 1970) Let A1, . . . , An and B1, . . . , Bn be distinct subsets of N such that: • every |Ai| = r and every |Bi| = s, • for every i, Ai ∩ Bi = ∅, and • for every i < j, Ai ∩ Bj ̸= ∅. Prove that n ≤ (r+s r ). Remark: this is much more diﬃcult, and the proof uses linear algebra. 4 6. (Erd˝os, 1965) A set S is called sum-free if there is no triple of (not necessarily distinct) elements x, y, z ∈ S satisfying x + y = z. Prove that every set A of nonzero integers contains a subset S ⊂ A of size |S| > |A|/3 which is sum-free. Solution: Choose a prime p of the form 3k + 2 such that p is greater than twice the maximum absolute value of any element in A. Let C = {k + 1, . . . , 2k + 1}, which is sum-free modulo p. Then pick a uniformly random x ∈ {1, . . . , p} and let B be the set obtained by multiplying each element of A by x, modulo p. For each element, probability of mapping into C is |C|/(p − 1) > 1/3. So expected number of elements mapping into C is > |A|/3, and we can take S to be those that do. 7. (Alon-Spencer, Exercise 2.9.) Suppose that every vertex of a n-vertex bipartite graph is given a personalized list of > log2 n possible colors. Prove that it is possible to give each vertex a color from its list such that no two adjacent vertices receive the same color. (This is a statement about the list-chromatic number of a bipartite graph.) Open: If the maximum degree of the bipartite graph is ∆, is it always possible to color from lists of size log2 ∆? Solution: Let the bipartition of the vertex set be V1 ∪ V2. Let X be the total set of all colors in all lists. For each color, independently ﬂip a fair coin. The idea is that we would be done if for every vertex in V1, we can choose a color that corresponds to a Head, and for every vertex in V2, we can choose a color that was a Tail. So, let N count the number of vertices for which this fails. Clearly, for each vertex v, the probability of failure is 2−|S(v)| < 1/n. Thus, by linearity of expectation, E [N ] < 1, and we are guaranteed a circumstance in which N = 0. 5","libVersion":"0.3.1","langs":""}