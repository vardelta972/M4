{"path":"iCloudDrive/bks/Combinatorics/Combinatorics/Probabilistic Method - Po-Shen Loh - MOP 2009.pdf","text":"Probabilistic Methods in Combinatorics Po-Shen Loh June 2009 1 Warm-up 2 Olympiad problems that can probably be solved 1. (Leningrad Math Olympiad 1987, Grade 10 elimination round) Let A1, . . . , As be subsets of {1, . . . , M }, and suppose that none of the Ai are subsets of each other. For each index i, let ai = |Ai|. Prove that s∑ i=1 1 (M ai) ≤ 1. Remark. This is also known as the Lubell-Yamamoto-Meshalkin inequality. Solution: Generate a random permutation σ = (x1, . . . , xM ) of [M ]. Let each Ei be the event that the set Ai appears as the initial segment of σ, i.e., that {x1, . . . , xai} = Ai. Since none of the Ai contain each other, the Ei are mutually exclusive. But each P [Ei] = (M ai)−1, so the LHS is P [∪Ei], and probabilities are always ≤ 1. 2. (Very slight simpliﬁcation of a problem in the MathLinks.ro 2008 contest) Let A1, . . . , An and B1, . . . , Bn be distinct ﬁnite subsets of N such that: • for every i, Ai ∩ Bi = ∅, and • for every i ̸= j, (Ai ∩ Bj) ∪ (Aj ∩ Bi) ̸= ∅. Prove that for every real number 0 ≤ p ≤ 1, ∑ i p|Ai|(1 − p) |Bi| ≤ 1. Remark. This result is due to Tuza (1985). Solution: Sample a random subset of the universe by taking each element with probability p. Let Ei be the event that everything in Ai got picked while everything in Bi was missed. These are disjoint events, so the LHS is the probability that some Ei occurred, hence ≤ 1. 1 3. (IMO Shortlist 2006/C3) Let S be a ﬁnite set of points in the plane such that no three of them are on a line. For each convex polygon P whose vertices are in S, let a(P ) be the number of vertices of P , and let b(P ) be the number of points of S which are outside P . Prove that for every real number x: ∑ P x a(P )(1 − x) b(P ) = 1, where the sum is taken over all convex polygons with vertices in S. Important: a line segment, a point, and the empty set are considered to be convex polygons of 2, 1, and 0 vertices, respectively. Solution: Randomly color the points in black and white, with a point receiving black with probability x. For each convex polygon P , let EP be the event that all vertices on the perimeter of P are black, and all vertices in P ’s exterior are white. These events are mutually exclusive, so the LHS is the probability that some Ep holds. But there is always some EP that always holds: consider the convex hull of all of the black points. 3 Linearity of expectation Deﬁnition. Let X be a random variable which takes values in some ﬁnite set S. Then the expected value of X, denoted E [X], is: E [X] = ∑ x∈S x · P [X = x] Use the following exercises to get used to the concept of expected value. 1. What is the expected number of heads in 101 tosses of a fair coin? Prove this formally from the deﬁnition. Solution: 101∑ i=0 i (101 i ) 1 2101 = 2 −101 101∑ i=1 i · 101 i ( 100 i − 1 ) = 2 −101 100∑ j=0 101(100 j ) = 2 −101 · 101 · 2100 = 101/2. 2. What is the expected number of heads in 1 toss of a coin which lands heads with probability 1/10? 3. Can you calculate the expected number of heads in 101 tosses of a coin which lands heads with probability 1/10? One of the most useful facts about the expected value is called linearity of expectation. Proposition. For any two not necessarily independent random variables X and Y , we have E [X + Y ] = E [X] + E [Y ]. Proof. This is essentially a consequence of the commutativity of addition. Following the deﬁnition: E [X + Y ] = ∑ x,y (x + y) · P [X = x, Y = y] = ∑ x,y x · P [X = x, Y = y] + ∑ x,y y · P [X = x, Y = y] = ∑ x ( x ∑ y P [X = x, Y = y] ) + ∑ y ( y ∑ x P [X = x, Y = y] ) = ∑ x (xP [X = x]) + ∑ y (yP [Y = y]) = E [X] + E [Y ] . 2 Now use that fact to solve the following problems. 1. Calculate the expected number of heads in 101 tosses of a coin which lands heads with probability 1/10. Solution: This is the sum of 101 random variables, each of which has expectation 1/10. 4 Olympiad problems one can expect to solve The key lemma is the following apparently trivial result. Lemma. Let X be a random variable. Then there is some point in the probability space where X ≥ E [X], and also some point in the probability space where X ≤ E [X]. Try these problems. 1. (Iran Team Selection Test 2008/6) Suppose 799 teams participate in a tournament in which every pair of teams plays against each other exactly once. Prove that there exist two disjoint groups A and B of 7 teams each such that every team from A defeated every team from B. Solution: Sample A as a random 7-set. Let X be the number of guys that are totally dominated by A. Letting d− v denote the in-degree of v, we have E [X] = ∑ v (d − v 7 )/(799 7 ). But ∑ v d− v = (799 2 ), which means that the average in-degree is exactly 399. By convexity, E [X] ≥ 799 · (399 7 )/(799 7 ) ≈ 800 · (1/2) 7 ≈ 6.25, which is enough since X is an integer. Pick 7 teams B from the dominated group. 2. (Russia 1996/4) In the Duma there are 1600 delegates, who have formed 16000 committees of 80 persons each. Prove that one can ﬁnd two committees having at least four common members. Solution: Simply select a random 2-set of committees. Calculate expected number of people in both committees, and use convexity of ∑ x 2 i ≥ n(avg) 2. More carefully: Sample a pair of committees uniformly at random (i.e., randomly pick one of the(16000 2 ) possible pairs). Let X be the number of people who are in both chosen committees. Note that X = X1 + · · · + X1600, where each Xi is the {0, 1}-random variable telling whether the i-th person was in both chosen committees. By linearity of expectation, E [X] = E [X1] + · · · + E [X1600] . The magic is that each E [Xi] is easy to calculate! Let ni be the number of committees that the i-th person belongs to. Then, each E [Xi] = P [i-th person is in both picked committees] = (ni 2 )/(16000 2 ). The only piece of information we know about the {ni} is that their sum ∑ i ni = 16000 · 80, so this suggests that we use convexity to bound E [X] in terms of the average of {ni}, which we denote by n = (16000 · 80)/1600 = 800: E [X] ≥ 1600 · (n 2 )/(16000 2 ) = 1600 · (800 2 )/(16000 2 ) = 1600 · 800 · 799 16000 · 15999 = 3.995. (One could see that since 799 ≈ 800 and 15999 ≈ 16000, the last fraction is roughly 1/400.) But by the Lemma, we know that some outcome of the probabilistic sampling produces an X ≥ 3.995. Since X is always an integer, that outcome must in fact have X ≥ 4. In particular, we conclude that some pair of committees has ≥ 4 common members. □ 3. (MOP Test 2008/7/2) Suppose that a, b, c are positive real numbers such that for every integer n, ⌊an⌋ + ⌊bn⌋ = ⌊cn⌋. Prove that at least one of a, b, c is an integer. 3 Remark. You may use the following well-known number-theoretic fact: if x is irrational, then the fractional parts of the multiples of x are equidistributed over the interval [0, 1]. In particular, if we choose n uniformly among {1, . . . , N }, then E [{xn}] → 1/2 as N → ∞. Solution: Suppose none of a, b, c are integers. Divide both sides by n and take the limit. This gives a + b = c, so we also know that the sum of fractional parts: {an} + {bn} = {cn}. (1) If x is irrational, then {xn} is equidistributed over the interval [0, 1]. In particular, if we choose n uniformly among {1, . . . , N }, then E [{xn}] → 1/2 as N → ∞. On the other hand, if x is rational with reduced form p/q, then {xn} has expectation tending to q−1 2q = 1 2 − 1 2q . So, it is in the interval [1/4, 1/2). Conclusion: for any noninteger x, E [{xn}] → t, with t ∈ [1/4, 1/2]. Taking the expectation of equation (??), and taking limits, we immediately see that the only way to have the equality is if E [{an}] and E [{bn}] both tend to 1/4, and E [{cn}] → 1/2. But the only way to get expecation 1/4 is when a, b are rational, and the only way to get the full expectation 1/2 is when c is irrational. Yet our ﬁrst deduction was that a + b = c, so we cannot have two rationals summing to one irrational. Contradiction. 4. (MOP Test 2007/7/1) In an n × n array, each of the numbers 1, 2, . . . , n appears exactly n times. Show that there is a row or a column in the array with at least √n distinct numbers. Solution: Choose a random row or column (2n choices). Let X be the number of distinct entries in it. Now X = ∑ Ii, where each Ii is the indicator variable of i appearing (possibly more than once) in our random row or column. Clearly, each E [Ii] = P [Ii ≥ 1]. To lower-bound this, observe that the worst-case is if all n appearances of i are in some √n × √n submatrix, which gives P [Ii ≥ 1] ≥ 2√n/(2n) = 1/√n. Hence by linearity, E [X] ≥ √n. 5. (IMO Shortlist 1999/C4) Let A be any set of n residues mod n2. Show that there is a set B of n residues mod n2 such that at least half of the residues mod n2 can be written as a + b with a ∈ A and b ∈ B. Solution: Make n independent uniformly random choices from the n2 residues, and collect them into a set B. Note that since we use independence, this ﬁnal set may have size < n. But if we still have A + B occupying at least half of the residues, then this is okay (we could arbitrarily augment B to have the full size n). Let X be the number of residues achievable as a + b. For each potential residue i, there are exactly n ways to choose some b for which A + b ∋ i, since |A| = n. Therefore, the probability that a given residue i appears in A + B is precisely 1 − (1 − n n2 )n. Then E [X] is exactly n2 times that, because there are n2 total residues. Hence it suﬃces to show that 1 − (1 − n n2 )n ≥ 1/2. But this follows from the bound 1 − 1 n ≤ e −1/n, using e ≈ 2.718. 6. (Austrian-Polish Math Competition 1997/8) Let n be a natural number and M a set with n elements. Find the biggest integer k such that there exists a k-element family of 3-element subsets of M , no two of which are disjoint. Solution: We need to be careful about case when n is small: for n ≤ 5, we can simply take everything. Otherwise, it is Erd˝os-Ko-Rado. 5 Real problems one can expect to prove These are interesting results from research mathematics (as opposed to Olympiad mathematics) that have very elegant probabilistic proofs. 4 1. (Erd˝os, 1965) A set S is called sum-free if there is no triple of (not necessarily distinct) elements x, y, z ∈ S satisfying x + y = z. Prove that every set A of nonzero integers contains a subset S ⊂ A of size |S| > |A|/3 which is sum-free. Solution: Choose a prime p of the form 3k + 2 such that p is greater than twice the maximum absolute value of any element in A. Let C = {k + 1, . . . , 2k + 1}, which is sum-free modulo p. Then pick a uniformly random x ∈ {1, . . . , p} and let B be the set obtained by multiplying each element of A by x, modulo p. For each element, probability of mapping into C is |C|/(p − 1) > 1/3. So expected number of elements mapping into C is > |A|/3, and we can take S to be those that do. 2. (Tur´an’s Theorem, numerical bound) Let G be a graph with n vertices and average degree d. Prove that one can ﬁnd a set S of pairwise non-adjacent vertices of size at least n d+1 . Remark. This is called an independent set, and the result is tight because a disjoint union of copies of Kd+1 has no independent set larger than n d+1 . Solution: Start with a random ordering of the vertices. If any vertex precedes all of its neighbors according to the ordering, then take it for S. Clearly this is an independent set. Let Iv be the event that vertex v is chosen. E [Iv] = 1 dv+1 , so by linearity of expectation, E [|S|] = ∑ v 1 dv+1 . By convexity, this is at least n · 1 d+1 . 3. (Component of research problem of Tao Jiang’s masters’ student) Let G be a graph whose vertices have been properly colored. Nothing is assumed about the number of colors used, except for the local fact that for every vertex v, the number of diﬀerent colors which appear on v’s neighbors is at most M . Prove that there is a set S of pairwise non-adjacent vertices, of size at least n d+1 . Solution: (Proof due to Benny Sudakov.) Start with a random ordering of the color classes. If any vertex’s color class precedes all of its neighbors’ color classes according to the ordering, then take the vertex for S. Again this is clearly an independent set. A proper coloring has the property that any v is diﬀerently colored from all of its neighbors, so at most M + 1 total colors appear on v and its neighbors. Thus the probability that v’s color is earliest in the permutation is at least 1 M +1 . Finish by linearity of expectation. 4. (Crossing Lemma) No matter how you draw a graph with V vertices and E edges in the plane, there will be ≥ E3 64V 2 pairs of crossing edges, as long as E ≥ 4V . Solution: Since planar graphs have E ≤ 3V − 6, we automatically ﬁnd that the crossing number is always ≥ E − (3V − 6) > E − 3V . Now take a drawing with, say, t crossings, and sample vertices randomly with probability p. V goes down to pV , E goes down to p2E, and cr goes down to p4t. But this new drawing needs to satisfy the above, so p4t > p2E − 3pV. Substituting p = 4V /E, we get the desired result. 6 Real problems one does not expect to prove, but are probably true Many of these come from the excellent book titled The Probabilistic Method, by Noga Alon and Joel Spencer. 1. (Sperner’s Lemma) Prove that the maximum antichain in 2 [n] has size ( n ⌊n/2⌋ ). That is, show that if F is a collection of subsets of {1, . . . , n} such that no two distinct sets A, B ∈ F satisfy A ⊂ B, then |F| ≤ ( n ⌊n/2⌋ ). Solution: Note that this is a special case of one of the ﬁrst problems in this handout. 5 The idea is given as a hint in Alon-Spencer. Take a random permutation σ and let the random variable X = #{i : σ(1), . . . , σ(i) ∈ F}. Consider E [X]. By deﬁnition of F, X is bounded by 1, and the events {σ(1), . . . , σ(K)} ∈ F are disjoint for distinct K. Let Nk be the number of subsets of size k in F. E [X] = n∑ k=1 P [{σ(1), . . . , σ(k)} ∈ F] = n∑ k=1 Nk(n k) ≥ n∑ k=1 Nk( n ⌊n/2⌋ ) . Since E [X] ≤ 1, we conclude that ∑ Nk is bounded by ( n ⌊n/2⌋ ), and we are done. 2. (Corollary: Littlewood-Oﬀord Lemma) Let x1, . . . , xn be nonzero real numbers, not necessarily distinct. Suppose that c1, . . . , cn are independent random variables, each of which is ±1 with equal probability. Prove that P [c1x1 + · · · + cnxn = 0] ≤ O( 1√ n ). Solution: First, we may assume all xi > 0 by ﬂipping the sign of any negative guy. (Since the ci are ±1 with equal probability, it won’t make a diﬀerence.) Consider any combination of (ci) which makes ∑ cixi = 0. Identify this with a subset of [n], based on which indices have ci = +1. Let the F be the collection of all such subsets of [n]. This is an antichain because if we had some S strictly contained in a larger T , then the sum ∑ cixi corresponding to T would be strictly larger since all xi > 0. By Sperner’s Lemma, we conclude that the number of ways to have (ci) making zero-sum is at most( n ⌊n/2⌋ ), and so the desired probability bound is this divided by 2n, which is of order 1√ n . 3. (Erd˝os-Ko-Rado Theorem) Let n ≥ 2k be positive integers, and let C be a collection of pairwise- intersecting k-element subsets of {1, . . . , n}, i.e., every A, B ∈ C has A ∩ B ̸= ∅. Prove that |C| ≤ (n−1 k−1). Remark. This corresponds to the construction which takes all subsets that contain the element 1, say. Solution: Pick a random k-set A from 2 [n] by ﬁrst selecting a random permutation σ ∈ Sn, and then picking a random index i ∈ [n]. Then deﬁne A = {σ(i), . . . , σ(i + k − 1)}, with indices after n wrapping around, of course. It suﬃces to show that P [A ∈ C] ≤ k/n. Let us show that conditioned on any ﬁxed σ, P [A ∈ C|σ] ≤ k/n, which will ﬁnish our problem. But this is equivalent to the statement that C can only contain ≤ k intervals (wrapping after n) of the form {i, . . . , i + k − 1}, which is easy to show. 4. (ChipLiar game, Alon-Spencer Theorem 14.2.1) Paul and Carole play a game on a board with positions labeled {0, 1, . . . , k}. Initially, n stones are at position k. Paul and Carole play for r rounds, where each round has the following structure: Paul names a subset S of the stones on the board, and then, Carole either moves all stones in S one position to the left, or moves all stones in Sc one position to the left. Any stone that is moved leftwards from 0 is discarded. If the number of stones on the board becomes 1 or 0, Carole loses. Prove that if n · ∑k i=0 (r i)2−r > 1, then Carole has a winning strategy. Solution: Perfect information game, so one of them has a winning strategy. Suppose it is Paul, and let him play it. Carole will respond by playing randomly. Note that if Paul indeed has winning strategy, then it can even always beat a random strategy. Calculate expected number of stones left on the board after r rounds. By linearity, this is n times the probability that a chip survives for r rounds. But with random play, each chip moves left Bin(r, 1/2) many times. So, expected number of surviving chips is: nP [Bin(r, 1/2) ≤ k] , which we are given to be greater than 1. Hence some play sequence will leave Carole with ≥ 2 stones, contradicting existence of Paul’s perfect strategy. 5. (Bollob´as, 1965) Let A1, . . . , An and B1, . . . , Bn be distinct subsets of N such that: 6 • every |Ai| = r and every |Bi| = s, • for every i, Ai ∩ Bi = ∅, and • for every i ̸= j, Ai ∩ Bj ̸= ∅. Prove that n ≤ (r+s r ). Solution: (Proof from Alon-Spencer.) Let the universe X be the union of all Ai and Bj. Take random permutation of X. Deﬁne event Xi to be that all elements of Ai precede all elements of Bi in permutation. Easy to check that all n of the events Xi are pairwise disjoint, and each P [Xi] = (r+s r )−1. But sum of probabilities is ≤ 1, so done. 6. (Lov´asz, 1970) Let A1, . . . , An and B1, . . . , Bn be distinct subsets of N such that: • every |Ai| = r and every |Bi| = s, • for every i, Ai ∩ Bi = ∅, and • for every i < j, Ai ∩ Bj ̸= ∅. Prove that n ≤ (r+s r ). Remark. This is much more diﬃcult, and the proof uses linear algebra. 7. (Alon-Spencer, Exercise 1.7) Let A1, . . . , An and B1, . . . , Bn be distinct subsets of N such that: • every |Ai| = r and every |Bi| = s, • for every i, Ai ∩ Bi = ∅, and • for every i ̸= j, (Ai ∩ Bj) ∪ (Aj ∩ Bi) ̸= ∅. Prove that n ≤ (r+s)r+s rrss . Solution: Plug into Tuza’s result above with p = r r+s or s r+s . Alternatively, we can do this directly as follows. Let X := ⋃n i=1 Ai ∪ Bi be the base set. Deﬁne p := r/(r + s), and consider a “coin” which has one side saying “A” and one side saying “B”, with the A-side appearing with probability p. For each element in X, independently ﬂip the coin. This deﬁnes a mapping f : X → {A, B}. Deﬁne the family of events {Ei}n 1 by having Ei occur when all elements x ∈ Ai have f (x) = A, and all elements y ∈ Bi have f (y) = B. By deﬁnition of the family of sets, it is impossible for Ei and Ej to occur simultaneously if i ̸= j, because in particular, there would exist some element in either Ai ∩ Bj or Aj ∩ Bi, and it could neither be A nor B. So, just as in the previous problem, consider the probability of any Ei occurring. Trivially, P (Ei) = pr(1 − p) s for any i. Since the events are disjoint, the total probability is npr(1 − p) s. Yet all probabilities are bounded by 1, so just as in the previous problem, n ≤ p−r(1 − p) −s, which turns out to be the desired bound. (In fact, this choice of p is optimal.) 7 Really harder problems 1. Prove that the Riemann Hypothesis has probability > 0 of being true. References [1] N. Alon and J. Spencer, The Probabilistic Method, 2nd ed., Wiley, New York, 2000. 7","libVersion":"0.3.1","langs":""}